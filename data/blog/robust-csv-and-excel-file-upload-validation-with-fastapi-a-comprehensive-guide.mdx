---
title: 'Robust CSV & Excel File Upload Validation with FastAPI: A Comprehensive Guide'
date: '2024-10-26'
lastmod: '2024-10-26'
tags:
  ['fastapi', 'python', 'csv', 'excel', 'validation', 'file upload', 'data validation', 'pydantic']
draft: false
summary: 'Learn how to build a robust and secure FastAPI application for validating CSV and Excel file uploads. This comprehensive guide covers everything from basic setup to advanced data validation techniques using Pydantic and other Python libraries.'
authors: ['default']
---

# Robust CSV & Excel File Upload Validation with FastAPI: A Comprehensive Guide

Handling file uploads is a common requirement in web applications. When dealing with data files like CSV and Excel, validation is crucial to ensure data integrity and prevent security vulnerabilities. This guide walks you through building a FastAPI application that validates CSV and Excel files effectively. We'll cover everything from setting up the project to implementing advanced validation techniques.

## Why Validate CSV and Excel Files?

Validating uploaded CSV and Excel files is essential for several reasons:

- **Data Integrity:** Ensures that the data conforms to the expected format, type, and constraints. Prevents corrupted or invalid data from entering your system.
- **Security:** Mitigates risks like code injection and denial-of-service attacks by validating file content and structure. Prevents malicious scripts or oversized files from harming your application.
- **Application Stability:** Prevents unexpected errors and crashes caused by malformed data, leading to a more stable and reliable application.
- **Data Consistency:** Enforces consistency across your dataset, facilitating data analysis and reporting.
- **User Experience:** Provides informative error messages to users, guiding them to correct invalid data before submission, improving the overall user experience.

## Setting Up Your FastAPI Project

First, let's create a new FastAPI project. Make sure you have Python installed (3.7+) and then install FastAPI and Uvicorn (an ASGI server):

```plaintext
pip install fastapi uvicorn python-multipart pandas openpyxl
```

- **fastapi:** The web framework itself.
- **uvicorn:** An ASGI server to run your FastAPI application.
- **python-multipart:** Required for handling file uploads in FastAPI.
- **pandas:** A powerful data analysis library for working with CSV and Excel data. Provides convenient data manipulation and validation capabilities.
- **openpyxl:** A Python library to read and write Excel files. Necessary if you want to support `.xlsx` file formats.

Now, create a file named `main.py` and add the following basic structure:

```plaintext
from fastapi import FastAPI, File, UploadFile, HTTPException
from typing import List
import pandas as pd

app = FastAPI()

@app.post("/upload")
async def upload_file(file: UploadFile):
    return {"filename": file.filename}

```

This code defines a simple FastAPI application with a single endpoint `/upload` that accepts a file upload. It currently just returns the filename, but we'll add validation logic soon.

To run the application, use the following command:

```plaintext
uvicorn main:app --reload
```

This will start the server on `http://127.0.0.1:8000`. You can access the interactive API documentation at `http://127.0.0.1:8000/docs`.

## Handling Different File Types (CSV and Excel)

The `/upload` endpoint currently accepts any file type. We need to distinguish between CSV and Excel files and process them accordingly. Let's modify the code to handle different file extensions:

```plaintext
from fastapi import FastAPI, File, UploadFile, HTTPException
from typing import List
import pandas as pd
import io

app = FastAPI()

ALLOWED_EXTENSIONS = {"csv", "xlsx", "xls"} # add xls for older excel files


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS


@app.post("/upload")
async def upload_file(file: UploadFile):
    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="Invalid file type. Only CSV and Excel files are allowed.")

    try:
        contents = await file.read()
        file_extension = file.filename.rsplit(".", 1)[1].lower()

        if file_extension == "csv":
            df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        elif file_extension in ["xlsx", "xls"]:
            df = pd.read_excel(io.BytesIO(contents))
        else:
            raise HTTPException(status_code=500, detail="Unexpected error processing the file.") #Should never happen

        # Perform validation on the DataFrame (explained in later sections)
        # ...

        return {"filename": file.filename, "message": "File uploaded and processed successfully"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")


```

**Explanation:**

- **`ALLOWED_EXTENSIONS`:** A set containing the allowed file extensions.
- **`allowed_file(filename)`:** A helper function that checks if a filename has an allowed extension.
- The `/upload` endpoint now checks the file extension before processing.
- `await file.read()` reads the file content as bytes.
- **`pandas.read_csv()`:** Used to read CSV files into a Pandas DataFrame. We use `io.StringIO` to treat the string content as a file-like object. The `decode('utf-8')` converts the byte content to a UTF-8 string, which is generally the most common encoding for CSV files.
- **`pandas.read_excel()`:** Used to read Excel files (both `.xlsx` and `.xls` formats) into a Pandas DataFrame. We use `io.BytesIO` to treat the bytes content as a file-like object.
- The `try...except` block handles potential errors during file processing, providing a more informative error message to the client.
- An `xlsx` or `xls` filename extension results in using the `pandas.read_excel` function to parse the file contents.
- Includes `xls` extension to the allowed file extensions and processing since this will be a common format.

## Basic Data Validation using Pandas

Now that we can read the file content into a Pandas DataFrame, let's implement some basic validation:

```plaintext
from fastapi import FastAPI, File, UploadFile, HTTPException
from typing import List
import pandas as pd
import io

app = FastAPI()

ALLOWED_EXTENSIONS = {"csv", "xlsx", "xls"}


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS


@app.post("/upload")
async def upload_file(file: UploadFile):
    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="Invalid file type. Only CSV and Excel files are allowed.")

    try:
        contents = await file.read()
        file_extension = file.filename.rsplit(".", 1)[1].lower()

        if file_extension == "csv":
            df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        elif file_extension in ["xlsx", "xls"]:
            df = pd.read_excel(io.BytesIO(contents))
        else:
            raise HTTPException(status_code=500, detail="Unexpected error processing the file.") #Should never happen

        # Basic Validation Example: Check for empty DataFrame
        if df.empty:
            raise HTTPException(status_code=400, detail="File is empty.")

        # Basic Validation Example: Check for required columns
        required_columns = ["name", "email", "age"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise HTTPException(status_code=400, detail=f"Missing required columns: {', '.join(missing_columns)}")


        # Perform more advanced validation here (explained in later sections)
        # ...

        return {"filename": file.filename, "message": "File uploaded and processed successfully"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")
```

**Explanation:**

- **Empty DataFrame Check:** `if df.empty:` raises an exception if the DataFrame is empty, indicating an empty file.
- **Required Columns Check:** We define a list of `required_columns`. We then check if each column exists in the DataFrame's columns. If any are missing, an exception is raised.

## Advanced Data Validation with Pydantic

Pydantic is a powerful library for data validation and parsing in Python. We can use it to define data models that enforce specific types and constraints on our data. First, install Pydantic:

```plaintext
pip install pydantic
```

Now, let's define a Pydantic model for our data:

```plaintext
from fastapi import FastAPI, File, UploadFile, HTTPException
from typing import List, Optional
import pandas as pd
import io
from pydantic import BaseModel, validator, ValidationError

app = FastAPI()

ALLOWED_EXTENSIONS = {"csv", "xlsx", "xls"}


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS

class DataRow(BaseModel):
    name: str
    email: str
    age: int

    @validator("email")
    def validate_email(cls, email: str):
        if "@" not in email:
            raise ValueError("Invalid email format")
        return email

    @validator("age")
    def validate_age(cls, age: int):
        if age < 0 or age > 150:
            raise ValueError("Age must be between 0 and 150")
        return age

@app.post("/upload")
async def upload_file(file: UploadFile):
    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="Invalid file type. Only CSV and Excel files are allowed.")

    try:
        contents = await file.read()
        file_extension = file.filename.rsplit(".", 1)[1].lower()

        if file_extension == "csv":
            df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        elif file_extension in ["xlsx", "xls"]:
            df = pd.read_excel(io.BytesIO(contents))
        else:
            raise HTTPException(status_code=500, detail="Unexpected error processing the file.") #Should never happen

        # Basic Validation Example: Check for empty DataFrame
        if df.empty:
            raise HTTPException(status_code=400, detail="File is empty.")

        # Basic Validation Example: Check for required columns
        required_columns = ["name", "email", "age"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise HTTPException(status_code=400, detail=f"Missing required columns: {', '.join(missing_columns)}")

        # Advanced Validation with Pydantic
        try:
            for index, row in df.iterrows():
                DataRow(**row.to_dict()) # Validate each row using the Pydantic model
        except ValidationError as e:
            raise HTTPException(status_code=400, detail=f"Validation error in row {index + 2}: {e}") # row index starts from 2 because of the header

        return {"filename": file.filename, "message": "File uploaded and processed successfully"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")

```

**Explanation:**

- **`DataRow(BaseModel)`:** Defines a Pydantic model with the fields `name` (string), `email` (string), and `age` (integer).
- **`@validator("email")`:** A Pydantic validator that ensures the email field contains the "@" symbol. If not, it raises a `ValueError`.
- **`@validator("age")`:** A Pydantic validator that ensures the age field is within the range of 0 to 150.
- **`for index, row in df.iterrows():`:** Iterates through each row of the DataFrame.
- **`DataRow(**row.to_dict())`:** Converts each row to a dictionary and then uses the dictionary to instantiate the `DataRow` model. This triggers the Pydantic validation.
- **`ValidationError`:** If the validation fails, a `ValidationError` is raised. We catch this exception and return a 400 error with a detailed error message, including the row number where the validation failed. We add 2 to the index when reporting the error to the user because rows are 0 indexed and excel header row will be the first row.

## Handling Missing Values and Optional Fields

Often, CSV and Excel files might contain missing values or optional fields. Pydantic allows you to handle these scenarios using `Optional` and the `allow_none` parameter in validators:

```plaintext
from fastapi import FastAPI, File, UploadFile, HTTPException
from typing import List, Optional
import pandas as pd
import io
from pydantic import BaseModel, validator, ValidationError

app = FastAPI()

ALLOWED_EXTENSIONS = {"csv", "xlsx", "xls"}


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS

class DataRow(BaseModel):
    name: str
    email: str
    age: Optional[int] = None  # Age is now optional

    @validator("email")
    def validate_email(cls, email: str):
        if "@" not in email:
            raise ValueError("Invalid email format")
        return email

    @validator("age", pre=True, allow_none=True)
    def validate_age(cls, age: Optional[int]):
        if age is None:
            return None
        if age < 0 or age > 150:
            raise ValueError("Age must be between 0 and 150")
        return age

@app.post("/upload")
async def upload_file(file: UploadFile):
    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="Invalid file type. Only CSV and Excel files are allowed.")

    try:
        contents = await file.read()
        file_extension = file.filename.rsplit(".", 1)[1].lower()

        if file_extension == "csv":
            df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        elif file_extension in ["xlsx", "xls"]:
            df = pd.read_excel(io.BytesIO(contents))
        else:
            raise HTTPException(status_code=500, detail="Unexpected error processing the file.") #Should never happen

        # Basic Validation Example: Check for empty DataFrame
        if df.empty:
            raise HTTPException(status_code=400, detail="File is empty.")

        # Basic Validation Example: Check for required columns
        required_columns = ["name", "email"] #age is no longer required
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise HTTPException(status_code=400, detail=f"Missing required columns: {', '.join(missing_columns)}")

        # Advanced Validation with Pydantic
        try:
            for index, row in df.iterrows():
                DataRow(**row.to_dict()) # Validate each row using the Pydantic model
        except ValidationError as e:
            raise HTTPException(status_code=400, detail=f"Validation error in row {index + 2}: {e}") # row index starts from 2 because of the header

        return {"filename": file.filename, "message": "File uploaded and processed successfully"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")
```

**Changes:**

- **`age: Optional[int] = None`:** The `age` field is now defined as `Optional[int]`, meaning it can be an integer or `None`. The `= None` provides a default value of `None` if the field is missing in the input data.
- **`@validator("age", pre=True, allow_none=True)`:**
  - `pre=True`: This tells Pydantic to run the validator _before_ attempting to convert the input to an integer. This is important because if the value is missing (represented as `NaN` by Pandas), Pydantic would normally try to convert `NaN` to an integer, which would raise an error.
  - `allow_none=True`: This tells the validator to accept `None` as a valid value.
- **`if age is None:`:** The validator now explicitly checks for `None` and returns `None` if it's encountered.

## Handling Different Column Names

Sometimes, the column names in the uploaded file might not match the field names in your Pydantic model. You can use the `alias` feature in Pydantic to map different column names to your model fields.

```plaintext
from fastapi import FastAPI, File, UploadFile, HTTPException
from typing import List, Optional
import pandas as pd
import io
from pydantic import BaseModel, validator, ValidationError, Field

app = FastAPI()

ALLOWED_EXTENSIONS = {"csv", "xlsx", "xls"}


def allowed_file(filename: str) -> bool:
    return "." in filename and filename.rsplit(".", 1)[1].lower() in ALLOWED_EXTENSIONS

class DataRow(BaseModel):
    full_name: str = Field(alias="Name")  # Map "Name" column to "full_name" field
    email_address: str = Field(alias="Email")  # Map "Email" column to "email_address" field
    age: Optional[int] = None

    @validator("email_address")
    def validate_email(cls, email_address: str):
        if "@" not in email_address:
            raise ValueError("Invalid email format")
        return email_address

    @validator("age", pre=True, allow_none=True)
    def validate_age(cls, age: Optional[int]):
        if age is None:
            return None
        if age < 0 or age > 150:
            raise ValueError("Age must be between 0 and 150")
        return age

@app.post("/upload")
async def upload_file(file: UploadFile):
    if not allowed_file(file.filename):
        raise HTTPException(status_code=400, detail="Invalid file type. Only CSV and Excel files are allowed.")

    try:
        contents = await file.read()
        file_extension = file.filename.rsplit(".", 1)[1].lower()

        if file_extension == "csv":
            df = pd.read_csv(io.StringIO(contents.decode('utf-8')))
        elif file_extension in ["xlsx", "xls"]:
            df = pd.read_excel(io.BytesIO(contents))
        else:
            raise HTTPException(status_code=500, detail="Unexpected error processing the file.") #Should never happen

        # Basic Validation Example: Check for empty DataFrame
        if df.empty:
            raise HTTPException(status_code=400, detail="File is empty.")

        # Check if the expected columns exist based on the aliases
        expected_columns = ["Name", "Email"] # Check based on the original column names
        missing_columns = [col for col in expected_columns if col not in df.columns]
        if missing_columns:
            raise HTTPException(status_code=400, detail=f"Missing required columns: {', '.join(missing_columns)}")


        # Advanced Validation with Pydantic
        try:
            for index, row in df.iterrows():
                DataRow(**row.to_dict()) # Validate each row using the Pydantic model
        except ValidationError as e:
            raise HTTPException(status_code=400, detail=f"Validation error in row {index + 2}: {e}") # row index starts from 2 because of the header

        return {"filename": file.filename, "message": "File uploaded and processed successfully"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing file: {str(e)}")
```

**Changes:**

- **`full_name: str = Field(alias="Name")`:** This tells Pydantic that the `full_name` field in the model should be populated from the column named "Name" in the DataFrame.
- **`email_address: str = Field(alias="Email")`:** Similarly, this maps the "Email" column to the `email_address` field.
- The column names checked for in the data frame are now based on the alias not the variable name.

## Error Handling and User Feedback

Providing informative error messages to the user is crucial for a good user experience. The current implementation raises `HTTPException` with a detail message. You can further enhance this by providing more specific and user-friendly error messages. You could create custom exception classes to provide structured errors.

## Security Considerations

- **File Size Limits:** Implement file size limits to prevent denial-of-service attacks. You can use FastAPI's `File` dependency with the `max_size` parameter.
- **File Type Validation:** The `allowed_file` function provides basic file type validation, but you might consider using more robust methods, such as checking the file's MIME type or file signature. However, these can be spoofed, so focusing on validating the _content_ is generally more secure.
- **Data Sanitization:** Sanitize the data before processing it to prevent code injection attacks. Be especially cautious when handling user-provided strings.
- **Temporary File Storage:** Store uploaded files in a temporary directory with appropriate permissions. Ensure that temporary files are deleted after processing.

## Conclusion

This guide provides a comprehensive approach to validating CSV and Excel file uploads in FastAPI. By combining Pandas for data manipulation and Pydantic for data validation, you can create a robust and secure application that ensures data integrity and improves the user experience. Remember to tailor the validation rules and error messages to your specific application requirements. Also, review the security considerations to ensure your application is protected against potential vulnerabilities.
