---
title: 'Monitor Apache Kafka with Prometheus: A Comprehensive Guide'
date: '2024-10-27'
lastmod: '2024-10-27'
tags:
  [
    'kafka',
    'prometheus',
    'monitoring',
    'observability',
    'jmx',
    'exporter',
    'metrics',
    'apache kafka',
    'alerting',
  ]
draft: false
summary: 'Learn how to effectively monitor your Apache Kafka cluster using Prometheus. This comprehensive guide covers JMX Exporters, configuration, metric selection, and best practices for Kafka monitoring.'
authors: ['default']
---

# Monitor Apache Kafka with Prometheus: A Comprehensive Guide

Apache Kafka is a distributed, fault-tolerant streaming platform widely used for building real-time data pipelines and streaming applications. Ensuring its health and performance is crucial for maintaining the reliability of your data infrastructure. Prometheus, a popular open-source monitoring and alerting toolkit, provides a powerful solution for monitoring Kafka. This guide provides a comprehensive walkthrough on how to monitor Kafka using Prometheus, covering everything from JMX exporters to alerting strategies.

## Why Monitor Kafka with Prometheus?

Monitoring Kafka with Prometheus offers several advantages:

- **Real-time Visibility:** Gain real-time insights into the performance and health of your Kafka cluster.
- **Historical Data Analysis:** Analyze historical data to identify trends, bottlenecks, and potential issues.
- **Proactive Alerting:** Configure alerts to automatically notify you of critical issues, allowing you to address them before they impact your applications.
- **Centralized Monitoring:** Integrate Kafka monitoring into your existing Prometheus ecosystem for a unified view of your infrastructure.
- **Open Source and Cost-Effective:** Leverage the benefits of an open-source solution without licensing costs.

## Prerequisites

Before you start, ensure you have the following:

- **Apache Kafka Cluster:** A running Kafka cluster that you want to monitor.
- **Prometheus Server:** A running Prometheus server. If you don't have one set up, follow the [Prometheus documentation](https://prometheus.io/docs/prometheus/latest/getting_started/) for installation instructions.
- **JMX Exporter:** You'll need a JMX Exporter to expose Kafka metrics in a format that Prometheus can understand. We'll cover this in detail below.
- **Basic Understanding of Kafka and Prometheus:** Familiarity with the concepts of Kafka topics, partitions, brokers, and Prometheus queries (PromQL).

## Step 1: Understanding Kafka Metrics

Kafka exposes a wealth of metrics that provide insights into its performance and health. These metrics are exposed via Java Management Extensions (JMX). Here are some key metric categories to monitor:

- **Broker Metrics:** Overall health and performance of Kafka brokers.
  - `kafka_server_BrokerTopicMetrics_MessagesInPerSec`: Rate of messages received by the broker. High values indicate heavy load.
  - `kafka_server_BrokerTopicMetrics_BytesInPerSec`: Rate of bytes received by the broker. Similar to MessagesInPerSec, but measures the size of the data.
  - `kafka_server_BrokerTopicMetrics_BytesOutPerSec`: Rate of bytes sent out by the broker. Indicates the amount of data being consumed.
  - `kafka_server_KafkaRequestHandlerPool_RequestHandlerAvgIdlePercent`: Average idle percentage of request handler threads. Low values may indicate thread starvation.
  - `kafka_server_ReplicaManager_LeaderCount`: Number of leader partitions on the broker. Uneven distribution can lead to hot spots.
  - `kafka_server_ReplicaManager_UnderReplicatedPartitions`: Number of partitions that are under-replicated. Indicates potential data loss risk.
  - `kafka_server_ControllerStats_OfflinePartitionsCount`: Number of offline partitions. Indicates a serious problem requiring immediate attention.
  - `kafka_log_Log_Size`: Total size of the Kafka log files. Helps in capacity planning.
- **Topic Metrics:** Performance of individual Kafka topics.
  - `kafka_topic_Topic_PartitionCount`: Number of partitions for a given topic.
  - `kafka_topic_Topic_BytesInPerSec`: Rate of bytes received for a given topic. Useful for understanding topic-specific load.
  - `kafka_topic_Topic_BytesOutPerSec`: Rate of bytes sent for a given topic. Useful for understanding topic-specific consumption.
  - `kafka_topic_Topic_MessagesInPerSec`: Rate of messages received for a given topic.
  - `kafka_topic_Topic_NumPartitions`: Number of partitions for a specific topic.
- **Consumer Group Metrics:** Performance of consumer groups consuming from Kafka topics.
  - `kafka_consumergroup_ConsumerGroup_Lag`: Consumer lag, the difference between the latest offset in the topic and the consumer's current offset. High lag indicates the consumer is falling behind. (Typically needs custom implementation depending on the consumer group tooling used).

## Step 2: Setting up the JMX Exporter

Prometheus cannot directly scrape JMX metrics. You need a JMX exporter to expose these metrics in a Prometheus-friendly format. There are several JMX exporters available, but we'll focus on the `jmx_exporter` from Prometheus.

**1. Download the JMX Exporter:**

Download the latest version of the `jmx_exporter` JAR file from the [Prometheus JMX Exporter Releases page](https://github.com/prometheus/jmx_exporter/releases). Place the JAR file on each Kafka broker server, ideally in a dedicated directory (e.g., `/opt/kafka/jmx_exporter`).

**2. Create a Configuration File:**

The JMX exporter uses a configuration file to define which JMX metrics to expose. Create a configuration file (e.g., `jmx_exporter.yml`) on each Kafka broker server, typically in the same directory as the JAR file. Here's an example configuration file that scrapes common Kafka metrics:

```plaintext
---
lowercaseOutputName: true
lowercaseOutputLabelNames: true

rules:
  - pattern: kafka.server<type=BrokerTopicMetrics, name=(.*)PerSec\>(OneMinuteRate|MeanRate|Count)
    name: kafka_server_broker_topic_metrics_$1
    labels:
      name: '$1'
    type: UNTYPED

  - pattern: kafka.server<type=KafkaRequestHandlerPool, name=(.*)IdlePercent\>(Value)
    name: kafka_server_kafka_request_handler_pool_$1
    type: UNTYPED

  - pattern: kafka.server<type=ReplicaManager, name=(.*)\>(Value)
    name: kafka_server_replica_manager_$1
    type: UNTYPED

  - pattern: kafka.controller<type=KafkaController, name=(.*)\>(Value)
    name: kafka_controller_$1
    type: UNTYPED

  - pattern: kafka.cluster<type=Partition, name=UnderReplicated, topic=(.*), partition=(.*)>(Value)
    name: kafka_cluster_partition_under_replicated
    labels:
      topic: '$1'
      partition: '$2'
    type: UNTYPED

  - pattern: kafka.log<type=Log, name=Size, topic=(.*), partition=(.*)>(Value)
    name: kafka_log_log_size
    labels:
      topic: '$1'
      partition: '$2'
    type: UNTYPED

  - pattern: kafka.server<type=ControllerStats, name=(.*)\>(Value)
    name: kafka_server_controller_stats_$1
    type: UNTYPED

  - pattern: java.lang<type=MemoryPoolManager,name=Metaspace Manager><>(Usage.committed)
    name: jvm_memory_metaspace_committed_bytes
    type: UNTYPED
```

**Explanation:**

- `lowercaseOutputName: true`: Converts metric names to lowercase.
- `lowercaseOutputLabelNames: true`: Converts label names to lowercase.
- `rules`: Defines a set of rules for mapping JMX attributes to Prometheus metrics.
  - `pattern`: A regular expression that matches the JMX attribute.
  - `name`: The name of the Prometheus metric.
  - `labels`: Labels to add to the Prometheus metric based on the JMX attribute.
  - `type`: The Prometheus metric type (e.g., GAUGE, COUNTER, UNTYPED). `UNTYPED` allows Prometheus to infer the type based on the data.

**Important Considerations for the Configuration:**

- **Customize:** This configuration file is a starting point. Tailor it to your specific needs and the metrics you want to monitor. Refer to the Kafka JMX documentation for a complete list of available metrics.
- **Performance:** Avoid scraping too many metrics, as it can impact Kafka's performance. Focus on the metrics that are most critical for monitoring.
- **Naming Conventions:** Use descriptive metric names and labels to make it easier to understand and query the data.

**3. Start Kafka with the JMX Exporter:**

Modify the Kafka startup script (`kafka-server-start.sh`) to include the JMX exporter. Add the following line to the beginning of the script:

```plaintext
export KAFKA_OPTS="$KAFKA_OPTS -javaagent:/opt/kafka/jmx_exporter/jmx_prometheus_javaagent-0.19.0.jar=8080:/opt/kafka/jmx_exporter/jmx_exporter.yml"
```

**Explanation:**

- `/opt/kafka/jmx_exporter/jmx_prometheus_javaagent-0.19.0.jar`: The path to the JMX exporter JAR file. Replace with the actual path. Adjust the version number as appropriate.
- `8080`: The port number on which the JMX exporter will listen for HTTP requests from Prometheus. Choose an available port.
- `/opt/kafka/jmx_exporter/jmx_exporter.yml`: The path to the JMX exporter configuration file. Replace with the actual path.

**4. Restart Kafka Brokers:**

Restart all Kafka brokers for the changes to take effect.

## Step 3: Configure Prometheus to Scrape Kafka Metrics

Now that the JMX exporter is running on each Kafka broker, you need to configure Prometheus to scrape the metrics.

**1. Edit the Prometheus Configuration File (`prometheus.yml`):**

Add a new job to the `scrape_configs` section of your `prometheus.yml` file:

```plaintext
scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka-broker-1:8080', 'kafka-broker-2:8080', 'kafka-broker-3:8080'] # Replace with your Kafka broker hostnames and ports
```

**Explanation:**

- `job_name`: A name for the scrape job (e.g., `kafka`).
- `static_configs`: Defines a list of static targets to scrape.
  - `targets`: A list of Kafka broker hostnames and ports where the JMX exporter is running. Replace `kafka-broker-1`, `kafka-broker-2`, and `kafka-broker-3` with the actual hostnames or IP addresses of your Kafka brokers.

**2. Reload Prometheus:**

Reload the Prometheus configuration file to apply the changes. You can usually do this by sending a `SIGHUP` signal to the Prometheus process. For example:

```plaintext
kill -HUP <prometheus_pid>
```

You can find the Prometheus PID using `ps aux | grep prometheus`.

## Step 4: Verify Metrics in Prometheus

After reloading Prometheus, verify that it is scraping the Kafka metrics correctly.

**1. Access the Prometheus Web UI:**

Open the Prometheus web UI in your browser (usually at `http://localhost:9090`).

**2. Query Kafka Metrics:**

In the Prometheus query browser, type a Kafka metric name (e.g., `kafka_server_broker_topic_metrics_messagesinpersec`) and execute the query. You should see the metric data being returned for each Kafka broker. You may need to wait a few minutes for Prometheus to scrape the metrics for the first time.

## Step 5: Create Useful Queries and Visualizations

Now that you're collecting Kafka metrics in Prometheus, you can create useful queries and visualizations to monitor your Kafka cluster. Here are some examples:

**1. Messages In Per Second per Broker:**

```promql
rate(kafka_server_broker_topic_metrics_messagesinpersec[5m])
```

This query calculates the rate of messages received per second for each Kafka broker over the last 5 minutes. This is a good indicator of overall load.

**2. Bytes In Per Second per Topic:**

```promql
rate(kafka_topic_topic_bytesinpersec[5m])
```

This query calculates the rate of bytes received per second for each Kafka topic over the last 5 minutes. This helps you understand which topics are experiencing the most traffic.

**3. Under-Replicated Partitions:**

```promql
kafka_server_replica_manager_underreplicatedpartitions
```

This query displays the number of under-replicated partitions. A value greater than 0 indicates a potential data loss risk and requires immediate attention.

**4. Controller Active Controller Count:**

```promql
kafka_server_activecontrollercount
```

This should always be `1`. A value other than `1` may indicate issues with Zookeeper or Controller availability.

**5. Visualize with Grafana:**

Integrate Prometheus with Grafana to create dashboards for visualizing Kafka metrics. Grafana provides a user-friendly interface for creating custom dashboards and visualizations. Here are some dashboard ideas:

- Overall broker performance (CPU usage, memory usage, network traffic)
- Topic-specific performance (messages in per second, bytes in per second, consumer lag)
- Replication status (under-replicated partitions, offline partitions)
- Consumer group lag

## Step 6: Configure Alerts

Alerting is crucial for proactively identifying and addressing issues in your Kafka cluster. Prometheus provides a powerful alerting mechanism.

**1. Create Alerting Rules:**

Create a file named `kafka_alerts.yml` (or similar) to define your alerting rules. Here's an example:

```plaintext
groups:
  - name: Kafka Alerts
    rules:
      - alert: KafkaBrokerOfflinePartitions
        expr: kafka_server_controller_stats_offlinepartitionscount > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: 'Kafka Broker has offline partitions'
          description: 'The Kafka broker has {{ $value }} offline partitions. This indicates a serious problem and requires immediate attention.'

      - alert: KafkaBrokerUnderReplicatedPartitions
        expr: kafka_server_replica_manager_underreplicatedpartitions > 0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'Kafka Broker has under-replicated partitions'
          description: 'The Kafka broker has {{ $value }} under-replicated partitions.  This indicates a potential data loss risk.'

      - alert: KafkaHighMessageRate
        expr: rate(kafka_server_broker_topic_metrics_messagesinpersec[5m]) > 10000 #Adjust this threshold to suit your specific needs
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'High message rate on Kafka Broker'
          description: 'Kafka Broker is experiencing a high message rate of {{ $value }} messages per second. Investigate potential bottlenecks.'
```

**Explanation:**

- `groups`: A list of alert groups.
  - `name`: The name of the alert group.
  - `rules`: A list of alert rules.
    - `alert`: The name of the alert.
    - `expr`: The Prometheus query that triggers the alert.
    - `for`: The duration for which the query must be true before the alert is triggered.
    - `labels`: Labels to add to the alert. The `severity` label is commonly used for routing alerts to different notification channels.
    - `annotations`: Additional information about the alert, including a `summary` and `description`.

**2. Configure Prometheus to Load Alerting Rules:**

Add the following line to the `rule_files` section of your `prometheus.yml` file:

```plaintext
rule_files:
  - 'kafka_alerts.yml' # Replace with the actual path to your alerting rules file
```

**3. Reload Prometheus:**

Reload the Prometheus configuration file to apply the changes.

**4. Configure Alertmanager:**

Alertmanager handles the de-duplication, grouping, and routing of alerts. You'll need to configure Alertmanager to receive alerts from Prometheus and send notifications to your desired channels (e.g., email, Slack, PagerDuty). Refer to the [Alertmanager documentation](https://prometheus.io/docs/alerting/latest/alertmanager/) for detailed instructions on configuration.

## Best Practices

- **Monitor Key Metrics:** Focus on monitoring the most important metrics for your Kafka cluster, such as broker performance, topic performance, and replication status.
- **Set Realistic Thresholds:** Carefully choose alert thresholds based on your specific environment and performance requirements.
- **Use Descriptive Metric Names and Labels:** Use clear and consistent naming conventions to make it easier to understand and query the data.
- **Automate Deployment:** Use configuration management tools (e.g., Ansible, Chef, Puppet) to automate the deployment and configuration of the JMX exporter and Prometheus.
- **Regularly Review and Update Monitoring:** Regularly review your monitoring configuration and update it as your Kafka cluster evolves.
- **Secure the JMX Exporter:** If exposing the JMX Exporter to a wider network, consider adding authentication and authorization.

## Conclusion

Monitoring Kafka with Prometheus is essential for ensuring the health and performance of your streaming platform. By following the steps outlined in this guide, you can gain real-time visibility into your Kafka cluster, proactively identify issues, and maintain the reliability of your data infrastructure. Remember to tailor the configuration and alerting rules to your specific needs and environment. Continuously refine your monitoring strategy as your Kafka cluster evolves to ensure you're always capturing the most critical information.

```

```
