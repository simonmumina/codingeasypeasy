---
title: 'Critical Kafka Metrics to Monitor in Production Apache: Performance & Stability'
date: '2024-01-26'
lastmod: '2024-01-27'
tags: ['kafka', 'apache kafka', 'monitoring', 'metrics', 'performance', 'production', 'broker', 'consumer', 'producer', 'operations', 'observability', 'alerting']
draft: false
summary: 'Comprehensive guide to the most critical Apache Kafka metrics for production monitoring, covering broker, producer, and consumer aspects, with practical examples and best practices for ensuring optimal performance and stability.'
authors: ['default']
---

# Critical Kafka Metrics to Monitor in Production Apache: Performance & Stability

Apache Kafka is a distributed, fault-tolerant, high-throughput streaming platform used for building real-time data pipelines and streaming applications.  In a production environment, maintaining the health and performance of your Kafka cluster is crucial.  Effective monitoring requires understanding and tracking key metrics. This post delves into the most important Kafka metrics you should be monitoring, covering brokers, producers, and consumers, providing practical examples and recommendations.

## Why Monitor Kafka Metrics?

Monitoring Kafka metrics offers several benefits:

*   **Early Problem Detection:**  Identify issues like broker failures, performance bottlenecks, and consumer lag before they impact your applications.
*   **Performance Tuning:** Understand how your cluster is performing and identify areas for optimization, like adjusting broker configuration or increasing partition counts.
*   **Capacity Planning:**  Forecast future resource needs based on current usage and growth patterns.
*   **Uptime Guarantee:**  Ensure the availability and reliability of your data streaming platform.
*   **Compliance and Auditing:** Maintain a record of performance and usage for compliance requirements.

## Key Kafka Metrics Categories

We'll categorize the crucial metrics into three main areas:

1.  **Broker Metrics:**  Focus on the health and performance of individual Kafka brokers.
2.  **Producer Metrics:**  Focus on the efficiency and reliability of producers sending data to Kafka.
3.  **Consumer Metrics:**  Focus on the performance and lag of consumers reading data from Kafka.

## 1. Broker Metrics: The Foundation of Your Kafka Cluster

Broker metrics provide insights into the overall health and performance of the Kafka nodes.  Here are the key metrics to watch:

**1.1. JVM Metrics (Garbage Collection, Heap Usage)**

*   **Metric:** `jvm.gc.count` and `jvm.gc.time.seconds` (or equivalent depending on your monitoring tool)
*   **Description:**  Measures the frequency and duration of garbage collection (GC) cycles. Excessive GC can pause broker operations and impact performance.
*   **Importance:** High GC frequency or long GC pauses indicate memory pressure or inefficient garbage collection configuration.
*   **Monitoring and Alerting:**  Set alerts for when GC time exceeds a certain threshold, for example, more than 10% of CPU time.
*   **Example (Prometheus Query):**
    ```promql
    rate(jvm_gc_collection_seconds_count[5m])
    ```

*   **Metric:** `jvm.memory.heap.usage` (or equivalent)
*   **Description:**  Tracks the heap memory usage of the JVM.
*   **Importance:**  High heap usage can lead to out-of-memory errors or increased GC activity.
*   **Monitoring and Alerting:** Alert when heap usage exceeds a defined threshold, such as 80% of the maximum heap size.
*   **Example (Prometheus Query):**
    ```promql
    jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"}
    ```

**1.2. Disk I/O Metrics**

*   **Metric:**  Disk read/write latency and throughput (e.g., metrics reported by `iostat` or CloudWatch for AWS).  Specifically monitor the disk used by the Kafka log directory.
*   **Description:**  Measures the time it takes to read from and write to disk and the rate at which data is being transferred.
*   **Importance:**  Kafka relies heavily on disk I/O.  Slow disk performance directly impacts throughput and latency.
*   **Monitoring and Alerting:**  Alert if disk latency exceeds a threshold (e.g., 10ms) or if disk throughput is consistently low.
*   **Example (using `iostat`):**  Monitor the `await` (average wait time) and `r/s` (reads per second) and `w/s` (writes per second) for the Kafka log disk.

**1.3. Network I/O Metrics**

*   **Metric:**  Network throughput and latency (e.g., metrics reported by `netstat` or CloudWatch).
*   **Description:**  Measures the amount of data being transferred over the network and the time it takes for packets to travel.
*   **Importance:** Network bottlenecks can limit Kafka's throughput and introduce latency.
*   **Monitoring and Alerting:**  Alert if network throughput is consistently high or if network latency increases significantly.

**1.4. Kafka Request Metrics**

*   **Metric:** `kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent,process=kafka.Kafka`
*   **Description:**  Average idle percentage of request handler threads.
*   **Importance:** Low idle percentage indicates the broker is overloaded and cannot handle incoming requests quickly enough.
*   **Monitoring and Alerting:** Alert if the idle percentage drops below a certain threshold (e.g., 20%).
*   **Example (JMX):**
    ```java
    import javax.management.*;
    import java.lang.management.ManagementFactory;

    public class KafkaJMX {
        public static void main(String[] args) throws Exception {
            MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
            ObjectName mbeanName = new ObjectName("kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent,process=kafka.Kafka");

            Object attributeValue = mbs.getAttribute(mbeanName, "Value");

            System.out.println("RequestHandlerAvgIdlePercent: " + attributeValue);
        }
    }
    ```
*   **Metric:** `kafka.server:type=KafkaRequestHandlerPool,name=RequestQueueSize,process=kafka.Kafka`
*   **Description:** The number of requests waiting to be processed by the request handler threads.
*   **Importance:** A constantly growing request queue indicates overload and potential latency issues.
*   **Monitoring and Alerting:** Alert if the queue size exceeds a threshold.

**1.5. ZooKeeper Connection Status**

*   **Metric:**  ZooKeeper connection status (check the `kafka.controller:type=Controller,name=ActiveControllerCount,process=kafka.Kafka` and related metrics).
*   **Description:**  Ensures that the Kafka brokers are properly connected to ZooKeeper, which is used for cluster management and coordination.
*   **Importance:**  A lost ZooKeeper connection can lead to cluster instability and data loss.
*   **Monitoring and Alerting:** Alert if any brokers lose their connection to ZooKeeper.

**1.6. Under-Replicated Partitions**

*   **Metric:** `kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions`
*   **Description:**  Number of partitions that have fewer replicas than the configured replication factor.
*   **Importance:** Under-replicated partitions indicate potential data loss if a broker fails.
*   **Monitoring and Alerting:**  Alert when the number of under-replicated partitions is greater than zero.

## 2. Producer Metrics: Optimizing Data Ingestion

Producer metrics provide insights into the performance and reliability of data being sent to Kafka.  Here's what you should track:

**2.1. Request Latency**

*   **Metric:** `kafka.producer:type=producer-metrics,client-id=*,name=request-latency-avg` and `kafka.producer:type=producer-metrics,client-id=*,name=request-latency-max`
*   **Description:**  Average and maximum time it takes for a producer to send a request and receive a response from the broker.
*   **Importance:** High latency indicates network issues, overloaded brokers, or producer configuration problems.
*   **Monitoring and Alerting:**  Alert when the average or maximum latency exceeds a defined threshold.

**2.2. Record Send Rate and Throughput**

*   **Metric:** `kafka.producer:type=producer-metrics,client-id=*,name=record-send-rate` and `kafka.producer:type=producer-metrics,client-id=*,name=byte-rate`
*   **Description:**  The rate at which records are being sent to Kafka and the total throughput in bytes per second.
*   **Importance:** These metrics help you understand the volume of data being ingested and identify potential bottlenecks.
*   **Monitoring and Alerting:** Monitor for unexpected drops in the send rate or throughput, which could indicate a producer issue.

**2.3.  Record Retries and Errors**

*   **Metric:** `kafka.producer:type=producer-metrics,client-id=*,name=record-retries` and `kafka.producer:type=producer-metrics,client-id=*,name=record-error-rate`
*   **Description:** The number of times a producer has to retry sending a record and the rate of errors encountered.
*   **Importance:** High retry counts and error rates indicate potential issues with the Kafka cluster, network, or producer configuration.
*   **Monitoring and Alerting:** Alert when the retry count or error rate exceeds a threshold.

**2.4. Compression Ratio**

*   **Metric:**  Calculate the compression ratio based on the uncompressed and compressed message sizes.
*   **Description:**  Indicates the effectiveness of compression.  A poor compression ratio might suggest the data isn't compressible or that the compression algorithm isn't optimal.
*   **Importance:** Good compression reduces network bandwidth and storage requirements.
*   **Monitoring and Alerting:**  Monitor the compression ratio and alert if it drops significantly below an expected value.  This will likely need to be application specific.

**Code Example (Java Producer with Metrics Listener):**

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.Metric;
import org.apache.kafka.common.MetricName;

import java.util.Map;
import java.util.Properties;
import java.util.concurrent.Future;

public class KafkaProducerExample {

    public static void main(String[] args) throws Exception {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("acks", "all");
        props.put("retries", 3);
        props.put("linger.ms", 1);
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        try (KafkaProducer<String, String> producer = new KafkaProducer<>(props)) {
            String topic = "my-topic";
            String key = "key1";
            String value = "value1";

            for (int i = 0; i < 100; i++) {
                ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value + i);
                Future<RecordMetadata> future = producer.send(record);

                // Asynchronously get the result and handle exceptions
                producer.send(record, (metadata, exception) -> {
                    if (exception != null) {
                        System.err.println("Error sending message: " + exception.getMessage());
                    } else {
                        System.out.println("Sent message to topic " + metadata.topic() +
                                " partition " + metadata.partition() +
                                " offset " + metadata.offset());
                    }
                });

            }
            producer.flush();

            //Accessing metrics (example)
            Map<MetricName, ? extends Metric> metrics = producer.metrics();
            for (Map.Entry<MetricName, ? extends Metric> entry : metrics.entrySet()) {
                System.out.println("Metric Name: " + entry.getKey().name() + ", Value: " + entry.getValue().metricValue());
            }


        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

## 3. Consumer Metrics: Tracking Data Consumption and Lag

Consumer metrics are essential for understanding how consumers are reading data from Kafka and identifying potential lag issues.

**3.1. Consumer Lag**

*   **Metric:**  `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*,topic=*,partition=*,name=records-lag-max`
*   **Description:**  The difference between the latest offset in a partition and the consumer's current offset.  Represents how far behind a consumer is from the latest data.
*   **Importance:** High consumer lag indicates that the consumer is not keeping up with the rate of incoming data.  This can lead to data processing delays and application problems.
*   **Monitoring and Alerting:**  Alert when the consumer lag exceeds a defined threshold.
*   **Example (using `kafka-consumer-groups.sh` script):**
    ```bash
    ./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-group
    ```
    This command will output the current lag for each partition consumed by the `my-group` consumer group.  Parse the output to extract the lag values.

**3.2. Records Consumed Rate**

*   **Metric:** `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*,topic=*,partition=*,name=records-consumed-rate`
*   **Description:**  The rate at which records are being consumed from Kafka.
*   **Importance:**  Helps you understand the consumption rate and identify potential bottlenecks or underutilized consumers.
*   **Monitoring and Alerting:**  Monitor for unexpected drops in the consumption rate.

**3.3.  Fetch Request Latency**

*   **Metric:**  `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*,name=fetch-latency-avg` and `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*,name=fetch-latency-max`
*   **Description:**  Average and maximum time it takes for a consumer to fetch data from the broker.
*   **Importance:** High latency indicates network issues, overloaded brokers, or consumer configuration problems.
*   **Monitoring and Alerting:**  Alert when the average or maximum latency exceeds a defined threshold.

**3.4.  Commit Latency**

*   **Metric:**  (Often requires custom instrumentation)  The time it takes for a consumer to commit its offsets to Kafka.
*   **Description:**  Measures the time required to persist the consumer's progress.
*   **Importance:** High commit latency can contribute to consumer lag and potential data reprocessing if the consumer restarts.
*   **Monitoring and Alerting:** Alert on high commit latency and investigate potential issues with the Kafka broker or consumer configuration.  Using asynchronous commits and tuning `enable.auto.commit` can help.

**Code Example (Java Consumer with Lag Monitoring and Offset Committing):**

```java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.errors.WakeupException;

import java.time.Duration;
import java.util.*;
import java.util.concurrent.atomic.AtomicBoolean;

public class KafkaConsumerExample {

    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "my-group");
        props.put("enable.auto.commit", "false");  // Disable auto-commit
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        final KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        final String topic = "my-topic";
        consumer.subscribe(Collections.singletonList(topic));

        final AtomicBoolean running = new AtomicBoolean(true);


        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            System.out.println("Shutting down consumer...");
            running.set(false);
            consumer.wakeup(); // Interrupt poll()
            try {
                Thread.currentThread().join();
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }));


        try {
            while (running.get()) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
                    // Process the record here
                }

                // Manually commit offsets after processing a batch of records
                if (!records.isEmpty()) {
                    try {
                        consumer.commitSync(); // Synchronous commit, adjust for performance
                        System.out.println("Offsets committed successfully.");
                    } catch (Exception e) {
                        System.err.println("Error committing offsets: " + e.getMessage());
                    }
                }


                // Check and Log Lag (basic example, requires more sophisticated implementation for production)
                List<PartitionInfo> partitionInfos = consumer.partitionsFor(topic);
                if (partitionInfos != null) {
                    for (PartitionInfo partitionInfo : partitionInfos) {
                        TopicPartition partition = new TopicPartition(topic, partitionInfo.partition());
                        long endOffset = consumer.endOffsets(Collections.singleton(partition)).get(partition);
                        long currentPosition = consumer.position(partition);
                        long lag = endOffset - currentPosition;
                        System.out.println("Partition: " + partition.partition() + ", Lag: " + lag);
                    }
                }


            }
        } catch (WakeupException e) {
            if (running.get()) throw e;
        } finally {
            consumer.close();
            System.out.println("Consumer closed.");
        }
    }
}
```

## Best Practices for Kafka Monitoring

*   **Choose a Monitoring Tool:**  Select a monitoring tool that integrates well with Kafka and provides the necessary metrics and alerting capabilities. Popular options include Prometheus, Grafana, Datadog, New Relic, and Dynatrace.
*   **Centralized Logging:** Implement centralized logging to collect logs from all Kafka components (brokers, producers, consumers) for troubleshooting and analysis.
*   **Automate Alerting:**  Configure alerts for critical metrics to notify you of potential issues in real-time.
*   **Establish Baselines:**  Establish baseline performance metrics for your Kafka cluster to identify deviations and anomalies.
*   **Regularly Review Metrics:** Regularly review Kafka metrics to identify trends and optimize your cluster's performance.
*   **Consider Kafka's Native JMX:** Kafka exposes many metrics through JMX. Leverage JMX exporters (like Prometheus's) to collect and monitor these values.
*   **Monitor ZooKeeper Health:**  Closely monitor ZooKeeper's health as it is vital for Kafka's operation.

## Conclusion

Monitoring Kafka metrics is essential for maintaining a healthy and performant data streaming platform.  By understanding the key metrics for brokers, producers, and consumers, you can proactively identify and resolve issues before they impact your applications. Implementing a robust monitoring strategy will enable you to optimize your Kafka cluster's performance, ensure data reliability, and maximize uptime.  Remember to tailor your monitoring and alerting strategies to your specific application requirements and cluster configuration.