---
title: 'How to Create Kafka Topics via Command Line: A Step-by-Step Guide'
date: '2024-10-27'
lastmod: '2024-10-27'
tags: ['kafka', 'apache kafka', 'kafka topic', 'kafka cli', 'kafka command line', 'kafka tutorial', 'kafka create topic', 'kafka administration']
draft: false
summary: 'Learn how to create Kafka topics using the command line interface (CLI). This step-by-step guide covers everything from prerequisites to advanced configurations, complete with practical code examples.'
authors: ['default']
---

# How to Create Kafka Topics via Command Line: A Step-by-Step Guide

Apache Kafka is a distributed, fault-tolerant streaming platform that's widely used for building real-time data pipelines and streaming applications. At the heart of Kafka's architecture lies the concept of *topics*. Topics are like categories or feeds to which data is published. Before you can start producing or consuming data, you need to create Kafka topics. This guide will walk you through creating Kafka topics using the command line interface (CLI), covering essential configurations and best practices.

## Prerequisites

Before you begin, ensure you have the following:

*   **Kafka Installation:** You need a working Kafka installation. This usually involves downloading Kafka from the Apache Kafka website and following the installation instructions relevant to your operating system.
*   **Zookeeper Running:** Kafka relies on Zookeeper for cluster management. Ensure Zookeeper is running before attempting to create topics. The Kafka installation often includes Zookeeper, or you can install a separate Zookeeper instance.
*   **Kafka Broker Running:** Your Kafka brokers need to be up and running. These are the nodes that actually store the data.

## Understanding Kafka Topics

A Kafka topic is a logical category or feed name to which records are published.  Each topic is divided into one or more *partitions*.  Partitions allow for parallel processing and increased throughput.  Key concepts to understand include:

*   **Partitions:** Each partition is an ordered, immutable sequence of records.
*   **Replication Factor:** The number of copies of each partition.  Replication ensures fault tolerance.
*   **Retention Policy:** How long messages are kept in the topic (e.g., based on time or size).
*   **Cleanup Policy:** Determines what happens to old data. Can be set to `delete` (oldest records are deleted) or `compact` (only the latest value for each key is retained).

## Creating Kafka Topics using `kafka-topics.sh`

The primary tool for managing Kafka topics via the command line is `kafka-topics.sh`, which is located in the `bin` directory of your Kafka installation.

### Basic Topic Creation

The most basic command to create a topic is:

```bash
./bin/kafka-topics.sh --create --topic <topic_name> --bootstrap-server <broker_address> --partitions <number_of_partitions> --replication-factor <replication_factor>
```

Let's break down each part of the command:

*   `./bin/kafka-topics.sh`:  The path to the `kafka-topics.sh` script. Make sure you are in the Kafka installation directory or provide the full path.
*   `--create`:  Specifies that you want to create a new topic.
*   `--topic <topic_name>`:  The name of the topic you want to create. Replace `<topic_name>` with your desired topic name (e.g., `my-topic`).
*   `--bootstrap-server <broker_address>`:  The address of one or more Kafka brokers. This is used to initially connect to the Kafka cluster.  Replace `<broker_address>` with the address of your Kafka broker (e.g., `localhost:9092` or `broker1:9092,broker2:9092`).  It's best practice to include multiple brokers for redundancy.
*   `--partitions <number_of_partitions>`:  The number of partitions for the topic.  More partitions allow for higher throughput through parallelism.  Consider your anticipated data volume and consumer groups when choosing the number of partitions.  Replace `<number_of_partitions>` with the desired number (e.g., `3`).
*   `--replication-factor <replication_factor>`:  The number of replicas for each partition.  A replication factor of 1 means no replication, which is not recommended for production environments. A replication factor of 3 is common. Replace `<replication_factor>` with the desired number (e.g., `3`).

**Example:**

To create a topic named `user-activity-topic` with 3 partitions and a replication factor of 2, using a Kafka broker running on `localhost:9092`, you would use the following command:

```bash
./bin/kafka-topics.sh --create --topic user-activity-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2
```

After running this command, you should see output indicating that the topic has been created.

### Verifying Topic Creation

After creating a topic, you can verify its existence and configuration using the `--describe` option:

```bash
./bin/kafka-topics.sh --describe --topic <topic_name> --bootstrap-server <broker_address>
```

**Example:**

To describe the `user-activity-topic` created earlier:

```bash
./bin/kafka-topics.sh --describe --topic user-activity-topic --bootstrap-server localhost:9092
```

This will output information about the topic, including its partitions, replication factor, and configuration.

### Configuring Topic Properties

You can configure various topic properties during creation or modification.  These properties control aspects like message retention, cleanup policy, and more.

#### Creating a Topic with Custom Configurations

You can use the `--config` option to specify custom configurations during topic creation:

```bash
./bin/kafka-topics.sh --create --topic <topic_name> --bootstrap-server <broker_address> --partitions <number_of_partitions> --replication-factor <replication_factor> --config <configuration_key>=<configuration_value>
```

**Example:**

To create a topic with a retention period of 7 days (604800000 milliseconds):

```bash
./bin/kafka-topics.sh --create --topic my-topic-with-retention --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 --config retention.ms=604800000
```

#### Modifying Topic Configurations

You can modify existing topic configurations using the `--alter` option:

```bash
./bin/kafka-topics.sh --alter --topic <topic_name> --bootstrap-server <broker_address> --config <configuration_key>=<configuration_value>
```

**Example:**

To change the retention period of the `my-topic-with-retention` topic:

```bash
./bin/kafka-topics.sh --alter --topic my-topic-with-retention --bootstrap-server localhost:9092 --config retention.ms=1209600000  # 14 days
```

To remove a configuration:

```bash
./bin/kafka-topics.sh --alter --topic my-topic-with-retention --bootstrap-server localhost:9092 --delete-config retention.ms
```

Commonly used topic configurations include:

*   `retention.ms`:  Message retention time in milliseconds.
*   `retention.bytes`:  Maximum size of the topic in bytes.
*   `cleanup.policy`:  `delete` (oldest messages are deleted) or `compact` (only the latest value for each key is retained).
*   `min.insync.replicas`:  Minimum number of replicas that must acknowledge a write for the write to be considered successful. This is important for data durability.

### Listing Topics

To list all available topics in your Kafka cluster, use the `--list` option:

```bash
./bin/kafka-topics.sh --list --bootstrap-server <broker_address>
```

**Example:**

```bash
./bin/kafka-topics.sh --list --bootstrap-server localhost:9092
```

This will print a list of all topic names.

### Deleting Topics

**Warning: Deleting a topic is a destructive operation and will result in data loss.**

To delete a topic, use the `--delete` option:

```bash
./bin/kafka-topics.sh --delete --topic <topic_name> --bootstrap-server <broker_address>
```

**Example:**

To delete the `my-topic-with-retention` topic:

```bash
./bin/kafka-topics.sh --delete --topic my-topic-with-retention --bootstrap-server localhost:9092
```

**Important:** Topic deletion might require enabling the `delete.topic.enable` configuration in your Kafka broker settings (set to `true`). If deletion fails, check your broker configuration and logs.

## Advanced Topic Configuration Considerations

When designing your Kafka topics, consider the following:

*   **Partitioning Strategy:**  Choose a partitioning strategy that distributes data evenly across partitions. This is crucial for maximizing throughput. The default partitioning strategy uses the key of the message to determine the partition.
*   **Key Considerations:** The key you choose for partitioning is crucial.  Messages with the same key will always go to the same partition.
*   **Consumer Groups:** Understand how consumer groups interact with partitions. Each partition is consumed by only one consumer within a consumer group.
*   **High Availability:** Aim for a replication factor greater than 1 to ensure data durability and availability in case of broker failures.  Consider using a replication factor of 3 for critical data.
*   **Performance Tuning:**  Monitor your Kafka cluster and adjust topic configurations as needed to optimize performance.  Factors to monitor include CPU usage, disk I/O, and network latency.

## Conclusion

Creating and managing Kafka topics via the command line is a fundamental skill for Kafka administrators and developers. By understanding the different options and configurations available, you can create topics that are optimized for your specific use case. Remember to plan your topic design carefully, considering factors like partitioning, replication, and retention policies. This guide provides a solid foundation for managing Kafka topics and ensuring the efficient and reliable flow of data in your streaming applications.  Always remember to back up your Kafka configurations before making major changes.