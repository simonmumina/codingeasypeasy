---
title: 'Property-Based Testing with FastAPI: A Comprehensive Guide using Hypothesis'
date: '2024-10-26'
lastmod: '2024-10-26'
tags:
  [
    'fastapi',
    'property-based testing',
    'hypothesis',
    'testing',
    'python',
    'api',
    'data validation',
    'fuzzing',
  ]
draft: false
summary: 'Learn how to integrate property-based testing with Hypothesis into your FastAPI applications to build more robust and reliable APIs.  This guide provides comprehensive code examples and explanations.'
authors: ['default']
---

# Property-Based Testing with FastAPI: A Comprehensive Guide using Hypothesis

Building robust and reliable APIs is crucial for any software project. Traditional unit testing, while essential, can sometimes miss edge cases and unexpected inputs. Property-based testing (PBT) offers a powerful alternative. It allows you to define _properties_ that should always hold true for your application, and then automatically generate numerous test cases to verify those properties. This blog post provides a comprehensive guide on how to integrate property-based testing using Hypothesis with FastAPI.

## What is Property-Based Testing?

Unlike traditional unit tests, where you define specific inputs and expected outputs, property-based testing focuses on defining the _properties_ that your code should satisfy for _any_ valid input. The testing framework then automatically generates many different inputs that satisfy your input constraints and verifies that the properties hold true for each generated input.

This approach has several advantages:

- **Discovers Edge Cases:** Property-based testing is excellent at finding edge cases and unexpected inputs that you might not have considered when writing traditional unit tests.
- **Reduced Boilerplate:** You define the properties once, and the framework handles generating various test cases, reducing the amount of code you need to write.
- **Improved Confidence:** By verifying properties across a wide range of inputs, you gain greater confidence in the correctness and robustness of your code.

## Why Use Hypothesis?

Hypothesis is a powerful Python library specifically designed for property-based testing. It offers a rich set of features, including:

- **Sophisticated Strategy Generation:** Hypothesis provides various _strategies_ for generating different types of data, such as integers, strings, dates, and even complex objects.
- **Automatic Shrinking:** When a test fails, Hypothesis automatically _shrinks_ the failing input to a minimal example that still causes the failure, making it easier to debug.
- **Integration with Existing Testing Frameworks:** Hypothesis integrates seamlessly with popular testing frameworks like pytest.
- **Customizable Strategies:** You can define your own custom strategies to generate data tailored to the specific needs of your application.

## Setting up your Environment

First, make sure you have FastAPI and Hypothesis installed. You can install them using pip:

```plaintext
pip install fastapi hypothesis pytest uvicorn
```

- `fastapi`: The web framework.
- `hypothesis`: The property-based testing library.
- `pytest`: A popular Python testing framework (Hypothesis works well with pytest).
- `uvicorn`: An ASGI server to run your FastAPI application.

## Example FastAPI Application

Let's create a simple FastAPI application that we can use to demonstrate property-based testing. This application will have a single endpoint that takes an integer as input and returns its square.

```plaintext
# main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, validator

app = FastAPI()


class NumberRequest(BaseModel):
    number: int

    @validator("number")
    def number_must_be_positive(cls, value):
        if value <= 0:
            raise ValueError("Number must be positive")
        return value


@app.post("/square")
async def calculate_square(request: NumberRequest):
    """
    Calculates the square of a positive integer.
    """
    number = request.number
    return {"square": number * number}
```

This application defines a `NumberRequest` model that enforces that the input number must be a positive integer using a Pydantic validator. The `/square` endpoint calculates and returns the square of the input number.

## Writing Property-Based Tests with Hypothesis

Now, let's write some property-based tests for our FastAPI application using Hypothesis. We'll focus on two key properties:

1.  **The output is always a positive number:** Since we only accept positive input, the square of the number should also always be positive.
2.  **The output is always greater than or equal to the input:** For positive numbers, the square is always greater than or equal to the original number.

Create a file named `test_main.py` in the same directory as your `main.py` file:

```plaintext
# test_main.py
from fastapi.testclient import TestClient
from hypothesis import given, strategies as st
from main import app, NumberRequest
import pytest


client = TestClient(app)


@given(number=st.integers(min_value=1, max_value=1000))
def test_square_is_positive(number: int):
    """
    Tests that the square of any positive integer is always positive.
    """
    response = client.post("/square", json={"number": number})
    assert response.status_code == 200
    data = response.json()
    assert data["square"] > 0


@given(number=st.integers(min_value=1, max_value=1000))
def test_square_is_greater_than_or_equal_to_input(number: int):
    """
    Tests that the square of any positive integer is always greater than or equal to the original number.
    """
    response = client.post("/square", json={"number": number})
    assert response.status_code == 200
    data = response.json()
    assert data["square"] >= number

@given(data=st.builds(NumberRequest, number=st.integers(min_value=1, max_value=1000)))
def test_square_is_correct_with_pydantic(data: NumberRequest):
    """
    Tests that the square calculation is correct using a Pydantic model
    and directly passing a Hypothesis strategy as input to the model.
    """
    response = client.post("/square", json=data.dict())
    assert response.status_code == 200
    response_data = response.json()
    assert response_data["square"] == data.number * data.number


@given(number=st.integers(max_value=0))
def test_non_positive_number_raises_error(number: int):
    """
    Tests that passing non-positive numbers raises a validation error.
    """
    response = client.post("/square", json={"number": number})
    assert response.status_code == 422  # Unprocessable Entity

```

Let's break down what's happening in this test file:

- **`from hypothesis import given, strategies as st`:** Imports the necessary components from Hypothesis. `given` is the decorator that marks a function as a property-based test. `strategies as st` provides a collection of predefined strategies for generating data.
- **`client = TestClient(app)`:** Creates a test client for our FastAPI application. This allows us to send requests to the API endpoints in our tests.
- **`@given(number=st.integers(min_value=1, max_value=1000))`:** This is the core of property-based testing. The `@given` decorator tells Hypothesis to generate many different values for the `number` argument. `st.integers(min_value=1, max_value=1000)` specifies that Hypothesis should generate integers between 1 and 1000 (inclusive).
- **`test_square_is_positive(number: int)`:** This is the test function. It receives the generated `number` as input. Inside the function:
  - We send a POST request to the `/square` endpoint with the generated number.
  - We assert that the response status code is 200 (OK).
  - We assert that the `square` value in the response JSON is greater than 0.
- **`test_square_is_greater_than_or_equal_to_input(number: int)`:** Similar to the previous test, but asserts that the `square` value is greater than or equal to the input `number`.
- **`test_square_is_correct_with_pydantic(data: NumberRequest)`:** This test uses `st.builds` to construct a `NumberRequest` object directly, leveraging Pydantic's validation and ensuring the data adheres to the model's constraints.
- **`test_non_positive_number_raises_error(number: int)`:** This test checks that the API returns a 422 (Unprocessable Entity) status code when given a non-positive number, demonstrating how Pydantic validation is correctly triggered.

## Running the Tests

To run the tests, use pytest:

```plaintext
pytest
```

Hypothesis will automatically generate hundreds (or even thousands) of test cases for each property. If any of the test cases fail, Hypothesis will automatically shrink the failing input to a minimal example that still causes the failure.

## Advanced Hypothesis Strategies

Hypothesis offers a wide range of strategies for generating different types of data. Here are some commonly used strategies:

- **`st.integers(min_value=None, max_value=None)`:** Generates integers within a specified range (or unbounded if no range is specified).
- **`st.floats(min_value=None, max_value=None, allow_nan=None, allow_infinity=None)`:** Generates floating-point numbers within a specified range (or unbounded if no range is specified). You can also control whether NaN and infinite values are allowed.
- **`st.text(min_size=0, max_size=None, alphabet=None)`:** Generates text strings. You can specify the minimum and maximum size of the strings, as well as the alphabet to use.
- **`st.booleans()`:** Generates boolean values (True or False).
- **`st.lists(elements, min_size=0, max_size=None)`:** Generates lists of elements. You can specify the strategy for generating the elements of the list, as well as the minimum and maximum size of the list.
- **`st.dictionaries(keys, values, min_size=0, max_size=None)`:** Generates dictionaries. You can specify the strategy for generating the keys and values, as well as the minimum and maximum size of the dictionary.
- **`st.dates(min_value=None, max_value=None)`:** Generates dates.
- **`st.datetimes(min_value=None, max_value=None, timezones=None)`:** Generates datetimes.
- **`st.sampled_from(elements)`:** Generates values from a fixed set of elements.
- **`st.one_of(strategies)`:** Generates values from one of the specified strategies.

## Custom Strategies

Sometimes, the predefined strategies are not sufficient for your needs. In these cases, you can define your own custom strategies using the `@st.composite` decorator.

For example, let's say you want to generate valid email addresses. You could define a custom strategy like this:

```plaintext
from hypothesis import strategies as st

@st.composite
def email_addresses(draw):
    """
    A strategy for generating valid email addresses.
    """
    username = draw(st.text(min_size=1, alphabet=st.characters(min_codepoint=97, max_codepoint=122))) # lowercase a-z
    domain = draw(st.text(min_size=1, alphabet=st.characters(min_codepoint=97, max_codepoint=122))) # lowercase a-z
    tld = draw(st.sampled_from(["com", "net", "org"]))
    return f"{username}@{domain}.{tld}"
```

In this example, the `email_addresses` function is decorated with `@st.composite`. The `draw` argument is a special function provided by Hypothesis that allows you to draw values from other strategies. The function generates a random username, domain, and top-level domain (TLD) and then combines them to create a valid email address. This strategy is a simplified example and doesn't cover all possible valid email addresses, but it demonstrates the basic principle. You would then need to import this into `test_main.py` and use it in a `given` decorator for your test.

## Integrating with Pydantic Models

As demonstrated in the example, you can directly integrate Hypothesis strategies with Pydantic models. This allows you to ensure that the generated data conforms to the validation rules defined in your Pydantic models. This is a crucial part of using property based testing with FastAPI, since FastAPI leverages Pydantic so heavily.

## Benefits of Property-Based Testing with FastAPI

- **Improved API Robustness:** Discover and address edge cases early in the development cycle.
- **Faster Development:** Automate test case generation, reducing the time spent writing individual tests.
- **Increased Confidence:** Verify that your API behaves as expected under a wide range of inputs.
- **Reduced Bugs:** Catch potential bugs and vulnerabilities that traditional unit tests might miss.

## Conclusion

Property-based testing with Hypothesis is a powerful technique for building more robust and reliable FastAPI applications. By defining properties that your code should satisfy and automatically generating numerous test cases, you can uncover edge cases, reduce boilerplate, and gain greater confidence in the correctness of your API. Integrating Hypothesis with Pydantic models further streamlines the testing process, ensuring that your data adheres to the validation rules defined in your application. Start incorporating property-based testing into your FastAPI projects today to build APIs that are more resilient and trustworthy.
