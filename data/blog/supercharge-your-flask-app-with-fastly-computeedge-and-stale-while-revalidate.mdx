---
title: 'Supercharge Your Flask App with Fastly Compute@Edge & Stale-While-Revalidate'
date: '2024-10-26'
lastmod: '2024-10-26'
tags:
  [
    'fastly',
    'compute-at-edge',
    'flask',
    'cdn',
    'stale-while-revalidate',
    'performance',
    'edge-computing',
    'python',
  ]
draft: false
summary: 'Learn how to dramatically improve the performance and scalability of your Flask application using Fastly Compute@Edge and the Stale-While-Revalidate (SWR) caching strategy. This guide provides a step-by-step tutorial with code examples for building high-performance web applications.'
authors: ['default']
---

# Supercharge Your Flask App with Fastly Compute@Edge & Stale-While-Revalidate

In today's fast-paced digital world, website performance is paramount. Slow loading times can lead to frustrated users, abandoned shopping carts, and a negative impact on your search engine rankings. Fortunately, technologies like Fastly's Compute@Edge and caching strategies like Stale-While-Revalidate (SWR) offer powerful solutions to significantly improve your application's responsiveness and scalability. This blog post will guide you through integrating Fastly Compute@Edge with a Flask application, leveraging the power of SWR to deliver blazing-fast experiences to your users.

## What is Fastly Compute@Edge?

Fastly Compute@Edge is a serverless compute environment that allows you to run code at the edge of Fastly's global network. This means your code executes closer to your users, reducing latency and improving performance. Unlike traditional CDNs that primarily cache static content, Compute@Edge allows you to perform dynamic computations and modifications to requests and responses _at the edge_, enabling complex functionalities without sacrificing speed.

Key benefits of Compute@Edge include:

- **Reduced Latency:** Execute code closer to users, minimizing round trip times.
- **Improved Performance:** Offload computation from your origin server, reducing load and improving response times.
- **Enhanced Security:** Implement custom security policies and protect your origin server from malicious traffic.
- **Greater Flexibility:** Customize request and response handling to meet specific application needs.

## What is Stale-While-Revalidate (SWR)?

Stale-While-Revalidate (SWR) is a caching strategy that prioritizes speed by serving stale (cached) content to the user immediately, while simultaneously revalidating the cache in the background. This ensures that users always see _something_ almost instantly, while the cache is updated asynchronously with the latest data. This approach is particularly effective for content that doesn't change drastically, providing a balance between freshness and speed.

**How SWR Works:**

1.  **Request Received:** A user requests a resource.
2.  **Cache Check:** The CDN checks its cache for the requested resource.
3.  **Cache Hit (Stale):** If the cached resource is found but considered "stale" (past its `max-age`), it's served to the user immediately.
4.  **Background Revalidation:** The CDN simultaneously sends a request to the origin server to update the cache with the latest version of the resource.
5.  **Cache Update:** Once the origin server responds, the cache is updated with the fresh resource. Subsequent requests will then receive the fresh, cached content (until it becomes stale again).
6.  **Cache Miss:** If the cached resource is not found, the request is forwarded to the origin server. The response from the origin server is then cached and served to the user.

## Setting up your Flask Application

First, let's create a simple Flask application that we'll use to demonstrate the integration.

```plaintext
from flask import Flask, jsonify, request
import time
import random

app = Flask(__name__)

# Simulate a database or external API call
def get_data():
    # Simulate some processing time
    time.sleep(0.5)
    # Return some dynamic data
    return {"message": f"Data generated at: {time.time()}", "random_number": random.randint(1, 100)}

@app.route('/data')
def data_endpoint():
    data = get_data()
    return jsonify(data)

if __name__ == '__main__':
    app.run(debug=True)
```

This Flask application exposes a `/data` endpoint that returns a JSON response containing a dynamic message and a random number. The `get_data()` function simulates a slow operation to highlight the benefits of caching.

## Configuring Cache Headers in Flask

To enable SWR, we need to set appropriate cache headers in our Flask application. Specifically, we'll use `Cache-Control` with `max-age` and `stale-while-revalidate` directives.

```plaintext
from flask import Flask, jsonify, request, make_response
import time
import random

app = Flask(__name__)

# Simulate a database or external API call
def get_data():
    # Simulate some processing time
    time.sleep(0.5)
    # Return some dynamic data
    return {"message": f"Data generated at: {time.time()}", "random_number": random.randint(1, 100)}

@app.route('/data')
def data_endpoint():
    data = get_data()
    response = jsonify(data)
    response.headers['Cache-Control'] = 'public, max-age=60, stale-while-revalidate=86400' # Cache for 60 seconds, stale for 1 day
    return response

if __name__ == '__main__':
    app.run(debug=True)
```

In this updated code, we've added the following `Cache-Control` header:

- `public`: Indicates that the response can be cached by any cache (CDN, browser, etc.).
- `max-age=60`: Specifies that the cache is valid for 60 seconds. After 60 seconds, the content is considered stale.
- `stale-while-revalidate=86400`: Specifies that the cache can serve stale content for up to 86400 seconds (1 day) while revalidating in the background.

This configuration means that the first request to `/data` will be served from the origin server. Subsequent requests within the first 60 seconds will be served from the cache. After 60 seconds, the cache will serve the _stale_ content, but it will simultaneously make a background request to the origin server to update the cache with the latest data. For up to 1 day after the initial cache, if the origin server isn't responding, the stale content will continue to be served.

## Setting up Fastly Compute@Edge

Now let's configure Fastly Compute@Edge to work with our Flask application. This involves deploying a Compute@Edge service that will handle incoming requests and interact with our Flask origin server.

**1. Create a Fastly Account:**

If you don't already have one, sign up for a Fastly account at [https://www.fastly.com/](https://www.fastly.com/).

**2. Install the Fastly CLI:**

Install the Fastly CLI to manage your Compute@Edge services:

```plaintext
npm install -g @fastly/cli
```

**3. Authenticate with Fastly:**

Authenticate the Fastly CLI with your account:

```plaintext
fastly authenticate
```

**4. Create a Compute@Edge Service:**

Create a new Compute@Edge project:

```plaintext
fastly compute init --name my-flask-app --language javascript
```

Choose `javascript` for the language. You can also use other supported languages like Rust. However, this example uses Javascript for simplicity.

**5. Modify the `src/index.js` file:**

Replace the contents of `src/index.js` with the following code. This Javascript code acts as the logic between the request from the user and the Flask server:

```plaintext
/// <reference types="@fastly/js-compute" />

import { CacheOverride, esi } from 'fastly:cache'

addEventListener('fetch', (event) => event.respondWith(handleRequest(event)))

async function handleRequest(event) {
  const url = new URL(event.request.url)
  // If request is to a specific path e.g. `/data`, forward request to origin
  if (url.pathname.startsWith('/data')) {
    // Define the backend to send the request to.
    const backend = 'origin'

    // Create a new Request object from the original request
    const req = new Request(event.request.url, event.request)

    // Always use HTTPS to the origin
    url.protocol = 'https:'
    req.url = url.toString()

    // Forward the request to the backend
    const response = await fetch(req, { backend })

    // Set a cache override, forcing caching if the origin didn't
    // and allowing for stale-while-revalidate
    const cacheOverride = new CacheOverride('override', { ttl: 60, staleWhileRevalidate: 86400 })
    response.cacheOverride = cacheOverride

    return response
  }

  // Respond to all other requests with a static response
  return new Response(
    `
  <html>
    <body>
      <h1>Hello from Fastly Compute@Edge!</h1>
      <p>Go to <a href="/data">/data</a> to see data from your Flask application.</p>
    </body>
  </html>
  `,
    {
      status: 200,
      headers: { 'Content-Type': 'text/html' },
    }
  )
}
```

This code does the following:

- It listens for fetch events, which represent incoming requests.
- If the request path starts with `/data`, it forwards the request to the origin server (our Flask application). This assumes you've configured a backend named "origin" in Fastly.
- For requests to `/data`, it sets a `CacheOverride` to enforce caching, including `staleWhileRevalidate`. This is crucial because even if your Flask server doesn't set caching headers correctly, Fastly will still cache the response based on this override.
- For all other requests, it returns a simple HTML page.
- It sets the `ttl` (time to live) to 60 seconds (max-age) and `staleWhileRevalidate` to 86400 seconds (1 day) in the CacheOverride.

**6. Configure the Fastly Backend:**

You need to configure a backend in your Fastly service to point to your Flask application. This tells Fastly where to send requests that are not served from the cache. You can do this through the Fastly web interface or via the CLI.

Using the CLI:

```plaintext
fastly backend create origin --address <YOUR_FLASK_APP_ADDRESS> --port 5000 --use-ssl true
```

Replace `<YOUR_FLASK_APP_ADDRESS>` with the public address of your Flask application (e.g., a domain name or IP address). If your Flask application uses HTTPS, set `--use-ssl true`. The default Flask port is 5000.

**7. Deploy the Compute@Edge Service:**

Deploy your Compute@Edge service using the Fastly CLI:

```plaintext
fastly compute publish
```

This will build and deploy your service to Fastly's edge network.

**8. Configure your Fastly Service (Via Web UI):**

- Log in to your Fastly account at [https://manage.fastly.com/](https://manage.fastly.com/)
- Find your new `my-flask-app` service.
- Configure a domain for your service so you can access it via a URL.
- You might need to configure additional settings such as SSL certificates.

## Testing the Setup

Once your Compute@Edge service is deployed, you can test the integration:

1.  **First Request:** Access your `/data` endpoint through your Fastly service's domain (e.g., `https://your-fastly-domain.com/data`). The first request will be slower as it needs to fetch the data from the origin server.
2.  **Subsequent Requests (within 60 seconds):** Refresh the page repeatedly within the first 60 seconds. You should see the same data being served from the cache very quickly.
3.  **Requests After 60 seconds:** After 60 seconds, refresh the page again. You should see the _old_ data served almost instantly (from the stale cache), but the data will be updated in the background. Refresh again shortly after, and you should see the _new_ data.
4.  **Verify Cache Headers:** Use your browser's developer tools to inspect the HTTP headers. You should see headers indicating that the content is being served from the Fastly cache (e.g., `Age`, `X-Cache`, `X-Cache-Hits`). After the max-age is exceeded, `X-Cache` may show `STALE`.

## Benefits of this Approach

- **Faster Load Times:** SWR ensures that users always see something quickly, even if the data is slightly outdated.
- **Reduced Origin Load:** Caching reduces the load on your Flask origin server, allowing it to handle more traffic.
- **Improved Scalability:** By offloading caching to the edge, your application can scale more easily to handle increasing user demand.
- **Resilience:** If your origin server experiences temporary issues, Fastly can continue to serve stale content from the cache, providing a more resilient user experience.
- **Cost Optimization:** By caching content at the edge, you can reduce your bandwidth costs and improve overall efficiency.

## Further Enhancements

- **Advanced Caching:** Explore more advanced caching strategies, such as using different cache keys based on user attributes or request parameters.
- **ESI (Edge Side Includes):** Use ESI to assemble pages from multiple cached fragments. This allows you to cache different parts of a page independently.
- **Image Optimization:** Integrate image optimization services within Compute@Edge to automatically optimize images for different devices and screen sizes.
- **Personalization:** Use Compute@Edge to personalize content based on user data or geographic location.

## Conclusion

Integrating Fastly Compute@Edge with your Flask application, using Stale-While-Revalidate caching, can dramatically improve performance, scalability, and resilience. By moving logic and caching to the edge, you can deliver a faster, more responsive experience to your users, while reducing the load on your origin server. This combination of technologies empowers you to build highly performant and scalable web applications that can meet the demands of today's digital landscape. Start experimenting with Compute@Edge and SWR today to unlock the full potential of your Flask application!
