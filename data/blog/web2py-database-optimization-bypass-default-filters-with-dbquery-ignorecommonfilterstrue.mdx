---
title: 'Web2py Database Optimization: Bypass Default Filters with db(query, ignore_common_filters=True)'
date: '2024-01-26'
lastmod: '2024-01-27'
tags:
  [
    'web2py',
    'database optimization',
    'web2py ORM',
    'python',
    'performance tuning',
    'ignore_common_filters',
  ]
draft: false
summary: 'Learn how to optimize your Web2py database queries by bypassing default filters using db(query, ignore_common_filters=True). Improve performance and understand when and how to use this powerful feature.'
authors: ['default']
---

# Web2py Database Optimization: Bypass Default Filters with `db(query, ignore_common_filters=True)`

Web2py is a powerful Python web framework known for its rapid development capabilities. However, like any web framework that interacts with a database, performance optimization is crucial for ensuring a smooth and responsive user experience. One key area for optimization in Web2py lies within its Object-Relational Mapper (ORM), particularly when dealing with complex queries and the framework's built-in default filters.

This article will delve into how to leverage the `db(query, ignore_common_filters=True)` functionality in Web2py to bypass these default filters and potentially boost your application's performance. We'll explore when and why you might want to use this feature, along with practical code examples to illustrate its usage.

## Understanding Web2py's Default Filters

Web2py's ORM is designed with security and data integrity in mind. As part of this design, it often applies default filters to your database queries. These filters can automatically handle tasks like:

- **Soft Deletes:** Instead of physically deleting records, Web2py can mark them as inactive (e.g., a `deleted` field set to `True`). Default filters prevent these "deleted" records from appearing in standard queries.
- **Tenant Filtering (Multi-tenancy):** In applications with multiple tenants or organizations, default filters can ensure that each tenant only sees their own data.
- **Active/Inactive Status:** Similar to soft deletes, records might have an `active` field indicating whether they are currently in use. Default filters might hide inactive records.

These default filters are generally beneficial and help prevent accidental exposure of sensitive data or unintended behavior. However, there are scenarios where bypassing these filters becomes necessary for optimization or specific use cases.

## The `ignore_common_filters=True` Parameter

The `db(query, ignore_common_filters=True)` parameter provides a mechanism to temporarily disable these default filters for a particular query. This is useful in scenarios where you need to access the full dataset, including records that would normally be hidden by the default filters.

**Syntax:**

```plaintext
rows = db(your_query, ignore_common_filters=True).select()
```

**When to Consider Using `ignore_common_filters=True`:**

- **Administrative Tasks:** When building administrative panels or reporting tools, you might need to access all records, including those that have been marked as deleted or inactive.
- **Data Migration:** During data migration or cleanup processes, accessing the complete dataset is often essential.
- **Specific Reporting Requirements:** Some reports may require the inclusion of records that are typically excluded by default filters.
- **Performance Optimization (Carefully):** In some cases, the default filters themselves can add overhead to your queries, especially when dealing with large datasets. By bypassing them and implementing more efficient filtering logic in your query, you might achieve performance gains. **However, proceed with caution and thorough testing, as bypassing default filters can have security implications if not handled correctly.**

## Code Examples

Let's illustrate the usage with a few concrete examples. Assume we have a table called `products` with fields like `id`, `name`, `price`, and `deleted` (a boolean field indicating if the product is deleted). By default, queries on the `products` table might exclude deleted products.

**Example 1: Retrieving All Products, Including Deleted Ones**

```plaintext
db.define_table('products',
    Field('name'),
    Field('price', 'decimal(10,2)'),
    Field('deleted', 'boolean', default=False)
)

# Insert some sample data
db.products.insert(name='Product A', price=10.00, deleted=False)
db.products.insert(name='Product B', price=20.00, deleted=True) # This product is marked as deleted
db.products.insert(name='Product C', price=15.00, deleted=False)

# Without ignore_common_filters, this will only return active products (deleted=False)
active_products = db(db.products).select()
print("Active Products:", len(active_products))  # Output: Active Products: 2

# Using ignore_common_filters=True, we retrieve all products, including the deleted one
all_products = db(db.products, ignore_common_filters=True).select()
print("All Products (including deleted):", len(all_products)) # Output: All Products (including deleted): 3

# Retrieving all products with explicit filtering
all_products_explicit = db(db.products).select() #This will implicitly add the default filter that products.deleted is False
print("All Products (explicit default filtering):", len(all_products_explicit)) # Output: All Products (explicit default filtering): 2
```

**Example 2: Combining `ignore_common_filters=True` with Specific Filtering**

Even when using `ignore_common_filters=True`, you can still apply your own specific filters to the query.

```plaintext
# Get all deleted products
deleted_products = db((db.products) & (db.products.deleted == True), ignore_common_filters=True).select()
print("Deleted Products:", len(deleted_products)) # Output: Deleted Products: 1
```

**Example 3: Optimizing a Query (Hypothetical - requires profiling)**

Let's imagine a scenario where the default `deleted` filter is causing a performance bottleneck due to complex indexing or table size. In this contrived example, we'll assume that checking `deleted == False` is slow. (In reality, this is unlikely to be the sole cause of a slow query, and proper indexing is usually the first step.)

```plaintext
# Slow Query (Hypothetical - profile your queries before making assumptions)
# Assume this query is slow because of the implicit deleted=False filter
#  AND other performance issues related to the implicit filtering
# and other factors
# and complex query with joins
#db.define_table('categories', Field('name'))
#db.define_table('product_categories', Field('product_id', 'reference products'), Field('category_id', 'reference categories'))

#db.categories.insert(name='Electronics')
#db.categories.insert(name='Books')

#db.product_categories.insert(product_id=1, category_id=1)
#db.product_categories.insert(product_id=1, category_id=2)
#db.product_categories.insert(product_id=2, category_id=1)
#db.product_categories.insert(product_id=3, category_id=2)

#products_with_electronics = db(db.products).select(left=db.product_categories.on(db.products.id==db.product_categories.product_id))

#Potentially faster query(depending on the database indexing and other factors, use EXPLAIN to verify it):
#products_with_electronics_optimized=db(db.products, ignore_common_filters=True).select()#left=db.product_categories.on(db.products.id==db.product_categories.product_id))


#This is just a contrived example, you should use EXPLAIN to see if you need ignore_common_filters
#The performance increase is not likely in this case, unless there is a very complicated default filtering logic.
```

**Important Considerations and Best Practices:**

- **Security:** Bypassing default filters can expose data that should be protected. Ensure you understand the implications and implement appropriate security measures to prevent unauthorized access. Carefully review the logic of your queries and any custom filtering you apply when using `ignore_common_filters=True`.
- **Testing:** Thoroughly test your application after using `ignore_common_filters=True` to verify that it behaves as expected and does not introduce any security vulnerabilities or data integrity issues.
- **Documentation:** Clearly document the use of `ignore_common_filters=True` in your code to explain why it's being used and any potential risks associated with it.
- **Understand Your Default Filters:** Before bypassing default filters, take the time to understand what they are doing and why they are in place. This will help you avoid accidentally breaking existing functionality or exposing sensitive data. Inspect the database model and web2py code to identify the global filters.
- **Indexing:** Proper database indexing is _crucial_ for performance. Before resorting to bypassing default filters, ensure that your tables are properly indexed to support your queries. Poor indexing is a far more common cause of slow queries than default filters. Use `EXPLAIN` statements in your database console to analyze your query plans and identify missing indexes.

## Conclusion

The `db(query, ignore_common_filters=True)` parameter in Web2py provides a powerful tool for bypassing default filters and accessing the full dataset. While it can be useful for administrative tasks, data migration, and specific reporting requirements, it should be used with caution due to the potential security implications. Always prioritize understanding your default filters, implementing proper security measures, and thoroughly testing your application before using this feature. Remember that indexing should always be the first point of call when optimising the performance of database queries.
