---
title: 'Optimize Database Queries in FastAPI: Async vs Sync for High Performance'
date: '2024-02-29'
lastmod: '2024-02-29'
tags:
  [
    'fastapi',
    'database',
    'optimization',
    'async',
    'sync',
    'performance',
    'sqlalchemy',
    'python',
    'orm',
  ]
draft: false
summary: 'Learn how to optimize database queries in FastAPI applications using both asynchronous (async) and synchronous (sync) approaches. This guide covers best practices, code examples, and performance considerations for building high-performance APIs.'
authors: ['default']
---

# Optimize Database Queries in FastAPI: Async vs Sync for High Performance

FastAPI is a modern, high-performance web framework for building APIs with Python 3.7+ based on standard Python type hints. When building APIs, interacting with databases is a common task. Optimizing these database interactions is crucial for ensuring your API remains responsive and scalable. This article dives into the strategies for optimizing database queries in FastAPI, focusing on both asynchronous (`async`) and synchronous (`sync`) approaches, helping you choose the right method for your specific use case and achieve optimal performance.

## Understanding Asynchronous vs. Synchronous Operations

Before diving into the code, let's clarify the difference between asynchronous and synchronous operations in the context of database interactions.

- **Synchronous (Sync) Operations:** In a synchronous operation, the program waits for the database query to complete before moving on to the next task. This means the thread executing the query is blocked until the results are returned. While simple to implement, synchronous operations can lead to performance bottlenecks, especially under high load.

- **Asynchronous (Async) Operations:** Asynchronous operations, on the other hand, allow the program to perform other tasks while the database query is being executed. This is achieved using `async` and `await` keywords in Python. The program can switch to other tasks and return to processing the query results when they are available. Asynchronous operations are essential for building highly concurrent and responsive applications.

## Choosing Between Async and Sync

The decision to use `async` or `sync` database operations in your FastAPI application depends on several factors:

- **Database Driver Support:** Not all database drivers have fully asynchronous support. Check if your database driver (e.g., `asyncpg` for PostgreSQL, `aiosqlite` for SQLite) offers native asynchronous capabilities. If not, using synchronous operations within an asynchronous context will still block the event loop and negate the benefits of `async`.

- **Complexity:** Asynchronous code can be more complex to write and debug compared to synchronous code. Consider the trade-off between performance gains and increased development effort.

- **Existing Codebase:** If you have an existing codebase with synchronous database interactions, migrating to asynchronous operations might require significant refactoring.

**General Guideline:** If you are building a new API and your database driver has solid asynchronous support, **always prefer asynchronous operations**. For existing codebases or scenarios where asynchronous support is limited, carefully evaluate the performance implications before making a decision.

## Implementing Asynchronous Database Queries with FastAPI

Let's explore how to implement asynchronous database queries using FastAPI and an asynchronous ORM (Object-Relational Mapper) like SQLAlchemy with `asyncpg` (for PostgreSQL).

**1. Install Required Packages:**

```bash
pip install fastapi uvicorn sqlalchemy asyncpg databases
```

**2. Database Configuration:**

```plaintext
import databases
import sqlalchemy
from fastapi import FastAPI

DATABASE_URL = "postgresql+asyncpg://user:password@host:port/database"  # Replace with your database connection string

database = databases.Database(DATABASE_URL)
metadata = sqlalchemy.MetaData()

# Define a sample table
users = sqlalchemy.Table(
    "users",
    metadata,
    sqlalchemy.Column("id", sqlalchemy.Integer, primary_key=True),
    sqlalchemy.Column("name", sqlalchemy.String(100)),
    sqlalchemy.Column("email", sqlalchemy.String(100)),
)

engine = sqlalchemy.create_engine(DATABASE_URL)  #For creating the database if it doesn't exist
metadata.create_all(engine)


app = FastAPI()


@app.on_event("startup")
async def startup():
    await database.connect()


@app.on_event("shutdown")
async def shutdown():
    await database.disconnect()
```

**Explanation:**

- We use the `databases` library which provides an asynchronous interface to SQLAlchemy core. It's built on top of SQLAlchemy but exposes `async` methods.
- `DATABASE_URL` should be replaced with your actual PostgreSQL connection string. Important: Ensure the driver specified here matches the connection string e.g., `postgresql+asyncpg`.
- We define a simple `users` table using SQLAlchemy's declarative syntax.
- The `startup` and `shutdown` events are used to connect to and disconnect from the database.

**3. Creating Asynchronous API Endpoints:**

```plaintext
from fastapi import Depends, HTTPException

# Define a model for user data (optional, but recommended)
from pydantic import BaseModel

class User(BaseModel):
    id: int
    name: str
    email: str

# Create a User model for inserting data
class UserCreate(BaseModel):
    name: str
    email: str


@app.post("/users/", response_model=User)
async def create_user(user: UserCreate):
    query = users.insert().values(name=user.name, email=user.email)
    last_record_id = await database.execute(query)
    return {**user.model_dump(), "id": last_record_id}


@app.get("/users/{user_id}", response_model=User)
async def read_user(user_id: int):
    query = users.select().where(users.c.id == user_id)
    user = await database.fetch_one(query)
    if user is None:
        raise HTTPException(status_code=404, detail="User not found")
    return user


@app.get("/users/", response_model=list[User])
async def read_users():
    query = users.select()
    return await database.fetch_all(query)


@app.put("/users/{user_id}", response_model=User)
async def update_user(user_id: int, user: UserCreate):
    query = users.update().where(users.c.id == user_id).values(name=user.name, email=user.email)
    rows_updated = await database.execute(query)
    if rows_updated == 0:
        raise HTTPException(status_code=404, detail="User not found")
    query = users.select().where(users.c.id == user_id)  #Fetch the updated user
    user_data = await database.fetch_one(query)
    return user_data

@app.delete("/users/{user_id}")
async def delete_user(user_id: int):
    query = users.delete().where(users.c.id == user_id)
    rows_deleted = await database.execute(query)
    if rows_deleted == 0:
        raise HTTPException(status_code=404, detail="User not found")
    return {"message": "User deleted"}

```

**Explanation:**

- Each endpoint function is declared as `async def`, indicating that it can perform asynchronous operations.
- We use `await` to pause execution until the database query is complete. This allows the FastAPI application to handle other requests while waiting for the database.
- The `database.execute()`, `database.fetch_one()`, and `database.fetch_all()` methods are used to execute SQL queries asynchronously.
- We use Pydantic models (`User`, `UserCreate`) for data validation and serialization.

## Implementing Synchronous Database Queries with FastAPI

If you need to use synchronous database operations (e.g., due to library limitations), you can run them in a separate thread to avoid blocking the main event loop. This is typically done using `asyncio.to_thread` (Python 3.9+) or a `ThreadPoolExecutor`.

**1. Install Required Packages:**

```bash
pip install fastapi uvicorn sqlalchemy psycopg2
```

**Note:** We use `psycopg2` (the synchronous PostgreSQL driver) here instead of `asyncpg`.

**2. Database Configuration:**

```plaintext
import sqlalchemy
from fastapi import FastAPI
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import asyncio

DATABASE_URL = "postgresql://user:password@host:port/database" # Replace with your database connection string.  Note the different scheme!

engine = create_engine(DATABASE_URL)
metadata = sqlalchemy.MetaData()

# Define a sample table
users = sqlalchemy.Table(
    "users",
    metadata,
    sqlalchemy.Column("id", sqlalchemy.Integer, primary_key=True),
    sqlalchemy.Column("name", sqlalchemy.String(100)),
    sqlalchemy.Column("email", sqlalchemy.String(100)),
)

metadata.create_all(engine)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

app = FastAPI()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

**Explanation:**

- We use the standard SQLAlchemy `create_engine` for synchronous database access.
- `DATABASE_URL` should be replaced with your actual PostgreSQL connection string suitable for a synchronous connection (using `postgresql://` instead of `postgresql+asyncpg://`).
- We create a `SessionLocal` class to manage database sessions.
- `get_db()` is a dependency injector that provides a database session to our API endpoints.

**3. Creating API Endpoints with Synchronous Database Operations:**

```plaintext
from fastapi import Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel

# Define a model for user data (optional, but recommended)
class User(BaseModel):
    id: int
    name: str
    email: str

# Create a User model for inserting data
class UserCreate(BaseModel):
    name: str
    email: str

async def run_in_threadpool(func, *args, **kwargs):
    """Run a synchronous function in a thread pool to avoid blocking the event loop."""
    return await asyncio.to_thread(func, *args, **kwargs)


@app.post("/users/", response_model=User)
async def create_user(user: UserCreate, db: Session = Depends(get_db)):

    def create_user_sync(user: UserCreate, db: Session):
        db_user = users.insert().values(name=user.name, email=user.email)
        result = db.execute(db_user)
        db.commit() # Ensure changes are persisted
        return result.inserted_primary_key[0]


    last_record_id = await run_in_threadpool(create_user_sync, user, db)
    return {**user.model_dump(), "id": last_record_id}

@app.get("/users/{user_id}", response_model=User)
async def read_user(user_id: int, db: Session = Depends(get_db)):

    def read_user_sync(user_id: int, db: Session):
        query = users.select().where(users.c.id == user_id)
        return db.execute(query).fetchone()

    user = await run_in_threadpool(read_user_sync, user_id, db)

    if user is None:
        raise HTTPException(status_code=404, detail="User not found")

    user_dict = dict(user._mapping) #Convert Row object to dict

    return user_dict

@app.get("/users/", response_model=list[User])
async def read_users(db: Session = Depends(get_db)):

    def read_users_sync(db: Session):
        query = users.select()
        results = db.execute(query).fetchall()
        return [dict(row._mapping) for row in results] #Convert each Row object to dict


    users_list = await run_in_threadpool(read_users_sync, db)

    return users_list

@app.put("/users/{user_id}", response_model=User)
async def update_user(user_id: int, user: UserCreate, db: Session = Depends(get_db)):

    def update_user_sync(user_id: int, user: UserCreate, db: Session):
        query = users.update().where(users.c.id == user_id).values(name=user.name, email=user.email)
        result = db.execute(query)
        db.commit()

        if result.rowcount == 0:
            return None  # User not found

        query = users.select().where(users.c.id == user_id)
        updated_user =  db.execute(query).fetchone()

        return dict(updated_user._mapping)

    updated_user = await run_in_threadpool(update_user_sync, user_id, user, db)

    if updated_user is None:
        raise HTTPException(status_code=404, detail="User not found")

    return updated_user


@app.delete("/users/{user_id}")
async def delete_user(user_id: int, db: Session = Depends(get_db)):

    def delete_user_sync(user_id: int, db: Session):
        query = users.delete().where(users.c.id == user_id)
        result = db.execute(query)
        db.commit()

        return result.rowcount

    rows_deleted = await run_in_threadpool(delete_user_sync, user_id, db)

    if rows_deleted == 0:
        raise HTTPException(status_code=404, detail="User not found")

    return {"message": "User deleted"}
```

**Explanation:**

- We use `asyncio.to_thread` (available in Python 3.9+) to run the synchronous database operations in a separate thread pool. This prevents the main event loop from being blocked. For older Python versions, use `loop.run_in_executor(None, func, *args)` where `loop = asyncio.get_event_loop()`. You'll need to initialize the event loop.
- Each endpoint function is declared as `async def`.
- The `create_user_sync`, `read_user_sync`, `read_users_sync`, `update_user_sync`, and `delete_user_sync` functions contain the synchronous database logic.
- We pass the database session (`db`) as a dependency to each endpoint.
- Remember to `commit()` any changes you make to the database.

## Optimizing Database Queries: General Best Practices

Regardless of whether you're using `async` or `sync` database operations, the following best practices can significantly improve your application's performance:

- **Use Indexes:** Indexes are crucial for speeding up queries that filter data based on specific columns. Ensure that you have appropriate indexes on columns used in `WHERE` clauses.

  ```sql
  CREATE INDEX idx_users_email ON users (email);
  ```

- **Optimize Queries:** Analyze your SQL queries using `EXPLAIN` to identify potential bottlenecks. Rewrite queries to use more efficient algorithms or avoid full table scans.

- **Use Connection Pooling:** Connection pooling reduces the overhead of establishing new database connections for each request. Both `databases` (async) and SQLAlchemy (sync) support connection pooling.

- **Limit Data Retrieval:** Only retrieve the columns you need in your queries. Avoid using `SELECT *` if you only need a subset of the data.

- **Use Pagination:** For large datasets, implement pagination to retrieve data in smaller chunks. This improves response times and reduces memory consumption. FastAPI provides built-in support for pagination using query parameters.

- **Cache Data:** Cache frequently accessed data to reduce the number of database queries. Use a caching library like Redis or Memcached. Consider both client-side and server-side caching.

- **Batch Operations:** For bulk inserts or updates, use batch operations to reduce the number of round trips to the database. SQLAlchemy's `bulk_insert_mappings` and `bulk_update_mappings` methods can be used for this purpose.

- **Connection Management:** Ensure you properly manage database connections. Close connections when they are no longer needed to release resources. With `databases` and SQLAlchemy ORM, this is usually handled by the session context manager.

- **Profile Your Code:** Use profiling tools to identify performance bottlenecks in your application. Python's `cProfile` module can help you pinpoint slow functions and database queries.

- **Use an ORM (Object-Relational Mapper):** ORMs, like SQLAlchemy, provide an abstraction layer over the database, making it easier to write and maintain database code. They also offer features like connection pooling and caching. However, be mindful of the performance overhead that ORMs can introduce. Sometimes raw SQL is more efficient for complex queries.

## Code Example: Using Indexes

```plaintext
# Assume you've already set up the FastAPI app and database connection
# and have data in your users table

@app.get("/users/by_email/{email}", response_model=User)
async def get_user_by_email(email: str):
    query = users.select().where(users.c.email == email)
    user = await database.fetch_one(query)
    if user is None:
        raise HTTPException(status_code=404, detail="User not found")
    return user
```

**Without an index on the `email` column**, this query would perform a full table scan to find the user with the matching email. **With an index (created above as `CREATE INDEX idx_users_email ON users (email);`)**, the query can quickly locate the user using the index, resulting in significantly faster performance, especially for large tables.

## Conclusion

Optimizing database queries is critical for building high-performance FastAPI applications. Choosing between asynchronous (`async`) and synchronous (`sync`) database operations depends on the database driver support and the complexity of your application. When possible, using asynchronous operations with an asynchronous database driver is recommended. Regardless of your choice, following general best practices, such as using indexes, optimizing queries, and caching data, will help you ensure your API remains responsive and scalable. Remember to profile your code and measure the performance impact of your optimizations. By carefully considering these factors and applying the techniques described in this article, you can build efficient and scalable FastAPI applications that meet the demands of your users.
