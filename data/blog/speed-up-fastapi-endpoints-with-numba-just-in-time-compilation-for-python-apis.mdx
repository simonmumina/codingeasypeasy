---
title: 'Speed Up FastAPI Endpoints with Numba: Just-In-Time Compilation for Python APIs'
date: '2024-10-26'
lastmod: '2024-10-26'
tags:
  [
    'fastapi',
    'numba',
    'jit',
    'just-in-time',
    'python',
    'api',
    'performance',
    'optimization',
    'web development',
  ]
draft: false
summary: "Learn how to significantly improve the performance of your FastAPI endpoints using Numba's Just-In-Time (JIT) compilation. This guide provides practical examples and best practices for optimizing your Python APIs for speed and efficiency."
authors: ['default']
---

# Speed Up FastAPI Endpoints with Numba: Just-In-Time Compilation for Python APIs

FastAPI is a modern, high-performance web framework for building APIs with Python 3.7+ based on standard Python type hints. It's known for its ease of use, automatic data validation, and built-in support for asynchronous operations. However, for computationally intensive tasks within your API endpoints, raw Python performance can still be a bottleneck. This is where Numba comes in.

Numba is a just-in-time (JIT) compiler for Python that translates Python functions into optimized machine code at runtime. By leveraging Numba, you can significantly speed up your CPU-bound FastAPI endpoints without the need for extensive code rewriting or switching to a different programming language.

This blog post will guide you through the process of using Numba with FastAPI to accelerate your API endpoints. We'll cover the basics of Numba, demonstrate how to apply it to FastAPI, and provide best practices for optimal performance.

## What is Numba?

Numba is an open-source, NumPy-aware optimizing compiler for Python. It works by translating Python functions (specifically, NumPy-using numerical functions) into optimized machine code using the LLVM compiler infrastructure. The key feature is its just-in-time (JIT) compilation.

**Key features of Numba:**

- **JIT Compilation:** Compiles Python code on the fly as it's being executed.
- **NumPy-Aware:** Works seamlessly with NumPy arrays, enabling significant speedups for numerical computations.
- **Ease of Use:** Simple decorators (`@jit`, `@njit`) make it easy to apply Numba to your functions.
- **Performance Gains:** Can significantly improve the performance of CPU-bound Python code, often achieving speeds comparable to C or Fortran.
- **Integration:** Integrates well with existing Python workflows.

## Setting up the Environment

Before we start, make sure you have the necessary packages installed. You can install FastAPI and Numba using pip:

```bash
pip install fastapi uvicorn numba
```

Also, consider using a virtual environment to manage your project dependencies. This is a good practice to avoid conflicts with other Python projects.

## Basic Example: Applying Numba to a Simple Function

Let's start with a simple example to illustrate how Numba works. We'll create a function that calculates the sum of squares and then use Numba to optimize it.

```plaintext
import time
from numba import njit

def sum_of_squares_python(n):
  """Calculates the sum of squares using pure Python."""
  result = 0
  for i in range(n):
    result += i * i
  return result

@njit
def sum_of_squares_numba(n):
  """Calculates the sum of squares using Numba JIT compilation."""
  result = 0
  for i in range(n):
    result += i * i
  return result


n = 1000000  # Example input size

# Measure execution time for pure Python
start_time = time.time()
sum_of_squares_python(n)
python_time = time.time() - start_time
print(f"Pure Python execution time: {python_time:.4f} seconds")

# Measure execution time for Numba
start_time = time.time()
sum_of_squares_numba(n) # First call triggers compilation
numba_time = time.time() - start_time
print(f"Numba (compilation) execution time: {numba_time:.4f} seconds")

start_time = time.time()
sum_of_squares_numba(n) # Second call benefits from compilation
numba_time = time.time() - start_time
print(f"Numba (optimized) execution time: {numba_time:.4f} seconds")

```

**Explanation:**

- We define two functions: `sum_of_squares_python` and `sum_of_squares_numba`.
- `sum_of_squares_python` is a standard Python function.
- `sum_of_squares_numba` is decorated with `@njit`. `@njit` is the "no python mode" JIT decorator. It forces Numba to compile the function entirely to machine code, potentially leading to significant speedups. If Numba _cannot_ compile the function to pure machine code, it will raise an error rather than fall back to using the Python interpreter. This makes debugging easier.
- When `sum_of_squares_numba` is called for the first time, Numba compiles it to machine code. Subsequent calls will use the compiled version, resulting in much faster execution. The first execution includes compilation time and will therefore likely be slower.

## Integrating Numba with FastAPI

Now, let's integrate Numba into a FastAPI application. We'll create a simple API endpoint that performs a computationally intensive task and use Numba to optimize it.

```plaintext
from fastapi import FastAPI
from numba import njit
import time

app = FastAPI()

@njit
def calculate_factorial(n):
  """Calculates the factorial of a number using Numba."""
  if n == 0:
    return 1
  else:
    return n * calculate_factorial(n-1)

@app.get("/factorial/{number}")
async def factorial_endpoint(number: int):
  """API endpoint to calculate the factorial of a number."""
  start_time = time.time()
  result = calculate_factorial(number)
  execution_time = time.time() - start_time
  return {"number": number, "factorial": result, "execution_time": execution_time}

```

**Explanation:**

- We define a FastAPI application using `app = FastAPI()`.
- We define a function `calculate_factorial` that calculates the factorial of a number. This is a good example because it's a recursive function and computationally intensive for larger numbers.
- We decorate `calculate_factorial` with `@njit` to enable Numba JIT compilation.
- We define a FastAPI endpoint `/factorial/{number}` that takes an integer as input, calculates its factorial using the `calculate_factorial` function, and returns the result along with the execution time.

**Running the Application:**

To run the application, save the code to a file (e.g., `main.py`) and use Uvicorn:

```bash
uvicorn main:app --reload
```

Now you can access the API endpoint in your browser or using a tool like `curl`:

```bash
curl http://127.0.0.1:8000/factorial/20
```

You should see a JSON response containing the factorial of 20 and the execution time. Try increasing the number to see the performance impact of Numba.

## Advanced Usage and Best Practices

- **Type Annotations:** Numba works best when it can infer the data types of variables and function arguments. Use type annotations (`: int`, `: float`, etc.) to help Numba optimize your code effectively. For example:

  ```plaintext
  from numba import njit, float64

  @njit(float64(float64)) #Specify the argument and return type
  def square(x):
      return x * x
  ```

- **NumPy Operations:** Numba is particularly effective with NumPy arrays. Use NumPy functions and operations whenever possible to take advantage of Numba's NumPy-aware optimization. Avoid explicit loops when NumPy provides vectorized alternatives.

- **Avoid I/O Operations:** Numba is designed for CPU-bound tasks. Avoid performing I/O operations (e.g., reading from or writing to files, database queries) within Numba-compiled functions, as they can negate the performance benefits. Perform I/O operations outside of the JIT-compiled regions of your code.

- **Cache Compilation:** You can cache the compiled version of a Numba function to disk, so it doesn't need to be recompiled every time the application starts. This can significantly reduce startup time.

  ```plaintext
  from numba import njit

  @njit(cache=True)
  def my_function(x):
      # ... your code ...
      pass
  ```

- **Use `parallel=True` for Suitable Loops:** For certain types of loops (especially those that can be executed independently), you can use the `parallel=True` option with `@njit` to enable automatic parallelization. This can further boost performance on multi-core processors.

  ```plaintext
  from numba import njit, prange

  @njit(parallel=True)
  def parallel_sum(arr):
      n = len(arr)
      result = 0.0
      for i in prange(n): # Use prange instead of range
          result += arr[i]
      return result
  ```

  Note: When using `parallel=True`, use `prange` instead of `range` in your loops.

- **Debugging:** Debugging Numba-compiled code can be tricky. If you encounter issues, try disabling Numba temporarily to isolate the problem. You can also use Numba's `debug` flag for more detailed debugging information.

- **Profiling:** Use profiling tools to identify performance bottlenecks in your code. This will help you determine which functions are most suitable for Numba optimization. Python's `cProfile` module is a good option.

## Caveats

- **Compilation Overhead:** The first time a Numba-compiled function is called, it incurs a compilation overhead. This can be significant for small functions. For this reason, Numba is most beneficial for computationally intensive tasks that are executed repeatedly.
- **Python Interpreter Compatibility:** Numba's `@njit` mode requires that all operations within the function can be translated to machine code. If Numba encounters an unsupported operation, it will raise an error. You may need to rewrite parts of your code to be compatible with Numba. Consider using `@jit` without `nopython=True` for compatibility, but this will likely result in less performance gain.
- **Object Mode:** When Numba cannot compile a function to pure machine code (due to unsupported features or data types), it falls back to "object mode," which uses the Python interpreter. Object mode is generally much slower than `@njit` mode.

## Conclusion

Numba is a powerful tool for accelerating CPU-bound Python code within FastAPI applications. By using Numba's JIT compilation, you can significantly improve the performance of your API endpoints without the need for extensive code rewriting. By understanding the basics of Numba and following the best practices outlined in this guide, you can unlock the full potential of your FastAPI applications and deliver a faster, more responsive user experience. Remember to profile your code to identify the most beneficial areas for optimization and to carefully consider the caveats of using Numba.
