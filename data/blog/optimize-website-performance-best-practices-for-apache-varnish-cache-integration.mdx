---
title: 'Optimize Website Performance: Best Practices for Apache + Varnish Cache Integration'
date: '2024-10-26'
lastmod: '2024-10-26'
tags:
  [
    'apache',
    'varnish cache',
    'web performance',
    'caching',
    'reverse proxy',
    'http cache',
    'vcl',
    'server optimization',
  ]
draft: false
summary: 'Unlock blazing-fast website speeds! This comprehensive guide provides best practices for integrating Apache with Varnish Cache, covering configuration, VCL scripting, debugging, and optimization techniques for maximum performance.'
authors: ['default']
---

# Optimize Website Performance: Best Practices for Apache + Varnish Cache Integration

Varnish Cache is a powerful HTTP reverse proxy designed to accelerate web applications by caching HTTP responses. When integrated effectively with Apache web server, it can significantly reduce server load, improve response times, and enhance the overall user experience. This comprehensive guide outlines the best practices for achieving seamless Apache and Varnish Cache integration.

## Why Integrate Apache and Varnish Cache?

- **Reduced Server Load:** Varnish intercepts incoming requests and serves cached content, freeing up Apache to handle dynamic requests only.
- **Improved Response Times:** Caching frequently accessed content in memory allows Varnish to deliver content much faster than Apache fetching it from the backend.
- **Enhanced User Experience:** Faster page load times directly translate to a better user experience, leading to increased engagement and conversions.
- **Increased Scalability:** By offloading static content serving to Varnish, you can handle more traffic with the same server infrastructure.
- **DDoS Protection:** Varnish can act as a buffer against certain types of DDoS attacks.

## Core Concepts

Before diving into the best practices, let's clarify a few key concepts:

- **Reverse Proxy:** Varnish sits in front of Apache, acting as an intermediary. Clients connect to Varnish, which then fetches content from Apache (the "backend") if it's not already cached.
- **HTTP Caching:** Varnish caches HTTP responses based on headers like `Cache-Control`, `Expires`, and `ETag`.
- **VCL (Varnish Configuration Language):** VCL is the scripting language used to configure Varnish's behavior, including cache policies, routing, and request manipulation.
- **Backend:** In this context, Apache is the backend server that Varnish proxies requests to.

## Best Practices for Apache + Varnish Cache Integration

### 1. Architectural Setup and Network Configuration

- **Port Configuration:** The most common configuration involves Varnish listening on port 80 (HTTP) or 443 (HTTPS), and Apache listening on a different port, such as 8080. This setup allows Varnish to intercept all incoming HTTP/HTTPS traffic.

  ```
  # Varnish listens on port 80
  varnishd -a :80 -T localhost:6082 -f /etc/varnish/default.vcl -s malloc,256m

  # Apache listens on port 8080
  Listen 8080
  <VirtualHost *:8080>
      ServerName yourdomain.com
      DocumentRoot /var/www/html
      ...
  </VirtualHost>
  ```

- **Firewall Configuration:** Ensure your firewall allows traffic to Varnish's port (80/443) and allows Varnish to communicate with Apache on its configured port (e.g., 8080).

- **Reverse Proxy Headers (X-Forwarded-For, X-Forwarded-Proto):** Configure Apache to recognize the `X-Forwarded-For` and `X-Forwarded-Proto` headers, which Varnish adds to the request to indicate the original client IP address and protocol (HTTP/HTTPS).

  ```plaintext
  # In your Apache VirtualHost configuration (e.g., /etc/apache2/sites-available/yourdomain.com.conf)
  <VirtualHost *:8080>
      ...
      RemoteIPHeader X-Forwarded-For
      RemoteIPInternalProxy 127.0.0.1
      RemoteIPInternalProxy ::1
      ...
  </VirtualHost>

  # Enable mod_remoteip if it's not already enabled
  a2enmod remoteip
  systemctl restart apache2
  ```

- **Keep Varnish and Apache on Separate Servers (Optional):** For high-traffic websites, consider running Varnish and Apache on separate servers to further distribute the load. This requires careful network configuration and potentially a load balancer in front of Varnish.

### 2. VCL Configuration: Crafting Your Caching Strategy

VCL is the heart of Varnish configuration. A well-defined VCL file is crucial for effective caching. Here's a breakdown of important VCL sections and best practices:

- **`vcl_recv`:** This subroutine is executed when Varnish receives a request from a client. Use it to:

  - **Normalize Requests:** Remove unnecessary query parameters, add trailing slashes, or modify headers.

    ```vcl
    sub vcl_recv {
      if (req.url ~ "\?(.*)$") {
        set req.url = regsub(req.url, "\?(.*)$", "");
      }
      if (req.url !~ "/$") {
          set req.url = req.url + "/";
      }
      return (hash);
    }
    ```

  - **Bypass Cache for Specific Requests:** Pass requests for admin pages, login forms, or API endpoints directly to Apache.

    ```vcl
    sub vcl_recv {
      if (req.url ~ "^/admin/") {
        return (pass);
      }
      if (req.http.Cookie ~ "wordpress_logged_in") {
        return (pass);
      }
      return (hash);
    }
    ```

  - **Handle Cookies:** Varnish generally does not cache responses with cookies. Carefully analyze which cookies are essential and which can be stripped. You can use the `vcl_hash` subroutine to selectively include cookies in the cache key. **Be cautious about caching responses with user-specific cookies, as this can lead to information leakage.**

- **`vcl_backend_response` (formerly `vcl_fetch`):** This subroutine is executed after Varnish fetches a response from Apache. Use it to:

  - **Set Cache TTL (Time-To-Live):** Determine how long content should be cached. Prioritize the `Cache-Control` header from Apache.

    ```vcl
    sub vcl_backend_response {
      if (beresp.http.Cache-Control) {
        return (deliver);
      }
      set beresp.ttl = 1h;  # Default cache time is 1 hour
      return (deliver);
    }
    ```

  - **Strip Unnecessary Headers:** Remove headers that are not needed by the client, such as `X-Powered-By`.

    ```vcl
    sub vcl_backend_response {
        unset beresp.http.X-Powered-By;
        return (deliver);
    }
    ```

  - **Handle Vary Header:** The `Vary` header indicates that the response varies based on certain request headers. Varnish needs to know this to cache the correct version.

    ```vcl
    sub vcl_backend_response {
      if (beresp.http.Vary) {
        set beresp.http.Vary = regsuball(beresp.http.Vary, "^ +| +$", "");
        if (beresp.http.Vary ~ "(?i)User-Agent") {
          # Handle User-Agent based variation - consider device detection libraries instead.
        }
      }
      return (deliver);
    }
    ```

- **`vcl_deliver`:** This subroutine is executed before Varnish delivers the response to the client. Use it to:

  - **Add Debugging Headers:** Include headers like `X-Cache: HIT` or `X-Cache: MISS` to easily check if the content was served from cache.

    ```vcl
    sub vcl_deliver {
      if (obj.hits > 0) {
        set resp.http.X-Cache = "HIT";
        set resp.http.X-Cache-Hits = obj.hits;
      } else {
        set resp.http.X-Cache = "MISS";
      }
      return (deliver);
    }
    ```

### 3. Apache Configuration: Optimizing for Varnish

- **Set Proper `Cache-Control` Headers:** Use `Cache-Control` headers in Apache to control Varnish's caching behavior.

  - `Cache-Control: public, max-age=3600`: Allow Varnish to cache the content for 1 hour.
  - `Cache-Control: private, max-age=0, must-revalidate`: Do not allow Varnish to cache the content.
  - `Cache-Control: no-cache, no-store, must-revalidate`: Same as above, but stronger.
  - `Cache-Control: s-maxage=604800, max-age=3600`: Cache for 1 hour on the client, but 1 week on the proxy (Varnish).

  You can set these headers in your Apache VirtualHost configuration or using `.htaccess` files.

  ```plaintext
  <Directory /var/www/html/images>
      <FilesMatch "\.(jpg|jpeg|png|gif)$">
          Header set Cache-Control "max-age=3600, public"
      </FilesMatch>
  </Directory>
  ```

- **Leverage `ETag` Headers:** Apache automatically generates `ETag` headers based on the content of the file. Varnish can use these `ETag` headers for conditional requests (If-None-Match), reducing bandwidth usage. Make sure `FileETag` is enabled in your Apache configuration.

  ```plaintext
  # In your Apache configuration (e.g., /etc/apache2/apache2.conf)
  FileETag INode MTime Size
  ```

- **Minimize Dynamic Content in Static Assets:** Wherever possible, avoid including dynamic content (e.g., session IDs, timestamps) in static assets like CSS and JavaScript files, as this prevents caching.

- **Keep-Alive Connections:** Ensure Keep-Alive is enabled in Apache. This allows Varnish to reuse existing connections to Apache, reducing latency.

  ```plaintext
  # In your Apache configuration (e.g., /etc/apache2/apache2.conf)
  KeepAlive On
  MaxKeepAliveRequests 100
  KeepAliveTimeout 5
  ```

### 4. Purging the Cache: Invalidating Stale Content

When content changes, you need to invalidate the corresponding cached entries in Varnish. Here are several methods for purging:

- **Ban:** The most common and recommended method. Bans allow you to invalidate cache entries based on patterns (e.g., URL prefixes).

  ```vcl
  sub vcl_recv {
    if (req.method == "PURGE") {
      if (client.ip != "127.0.0.1") { # Only allow purging from localhost for security
        return (synth(405, "Not allowed."));
      }
      ban("req.http.host == " + req.http.host + " && req.url == " + req.url);
      return (synth(200, "Purged."));
    }
    return (hash);
  }
  ```

  **Important Security Considerations:** The above code allows purging only from localhost. You should implement a more robust authentication mechanism (e.g., API key) for purging in a production environment.

- **URL Based Purge (Less Recommended):** Purging by URL is less efficient than banning because it requires Varnish to search through the cache.

- **varnishadm Command:** Use the `varnishadm` command to execute ban commands from the command line.

  ```bash
  varnishadm "ban req.url ~ '^/blog/'"
  ```

- **Implement Automatic Purging:** Integrate purging with your CMS or application to automatically invalidate cache entries when content is updated. Many CMS plugins and libraries are available for this purpose.

### 5. Monitoring and Debugging

- **`varnishstat`:** Provides real-time statistics about Varnish's performance, including cache hit ratio, request rates, and error counts.

- **`varnishlog`:** Captures HTTP requests and responses processed by Varnish, allowing you to analyze caching behavior.

- **`varnishhist`:** Displays a histogram of request latencies, helping you identify performance bottlenecks.

- **Adding `X-Cache` Headers:** As mentioned earlier, adding the `X-Cache: HIT` or `X-Cache: MISS` header to responses makes it easy to verify caching behavior in your browser's developer tools.

- **Check Apache Logs:** If Varnish is consistently missing the cache, check Apache's logs for errors or slow response times that might be preventing Varnish from caching properly.

### 6. HTTPS/SSL Configuration

- **Varnish can handle SSL termination directly (recommended):** Using a TLS proxy in front of Varnish (e.g., Hitch or Stunnel) or enabling TLS directly in Varnish (version 4.1 and later) offers better performance than having Apache handle the SSL connection.

  - **Hitch Example:** Hitch is a lightweight TLS proxy specifically designed for Varnish.

  ```
  # Hitch Configuration (hitch.conf)
  frontend = "[*:443]"
  backend = "127.0.0.1:6081" # Varnish listening port
  daemon = on
  ciphers = "ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-GCM-SHA384:!aNULL:!eNULL:!LOW:!EXPORT:!DES:!MD5:!PSK:!RC4"
  tls-protos = "TLSv1.2 TLSv1.3"
  ```

- **Apache handling SSL:** If Apache handles SSL, make sure Varnish is configured to forward the `X-Forwarded-Proto: https` header to Apache so that Apache generates the correct URLs. This is handled by default when configuring `RemoteIPHeader` as shown earlier.

### 7. Optimizing VCL for Performance

- **Keep VCL Simple and Efficient:** Avoid complex logic in your VCL, as it can slow down request processing. Use regular expressions sparingly and optimize them if necessary.
- **Use Subroutines:** Organize your VCL code into subroutines to improve readability and maintainability.
- **Test VCL Changes Carefully:** Always test your VCL changes in a staging environment before deploying them to production. Use `varnishlog` to verify that your changes are working as expected.
- **Regularly Review and Update VCL:** As your website evolves, regularly review and update your VCL to ensure it's still optimized for your current needs.

### 8. Content Delivery Network (CDN) Integration

If you're using a CDN, Varnish typically sits _behind_ the CDN. The CDN handles caching and distribution across multiple servers, while Varnish provides an additional layer of caching and request processing.

- **Configure CDN to Forward Requests to Varnish:** Make sure your CDN is configured to forward requests to Varnish's IP address and port.
- **Adjust Varnish's TTL:** Set appropriate TTL values in Varnish, taking into account the CDN's caching behavior. Generally, you'll want Varnish's TTL to be shorter than the CDN's TTL.
- **Handle CDN Purging:** You'll need to configure a mechanism for purging both the CDN and Varnish when content changes. Many CDN providers offer APIs for purging their cache.

## Conclusion

Integrating Apache with Varnish Cache can dramatically improve your website's performance and scalability. By following these best practices, you can configure Varnish to effectively cache your content, reduce server load, and deliver a faster, more responsive user experience. Remember to monitor Varnish's performance regularly and adjust your configuration as needed to optimize for your specific website and traffic patterns.
