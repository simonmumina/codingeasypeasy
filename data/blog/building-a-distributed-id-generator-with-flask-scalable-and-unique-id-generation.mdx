---
title: 'Building a Distributed ID Generator with Flask: Scalable and Unique ID Generation'
date: '2024-10-26'
lastmod: '2024-10-26'
tags:
  [
    'distributed systems',
    'id generation',
    'flask',
    'python',
    'snowflake',
    'redis',
    'database',
    'scalability',
    'unique id',
    'microservices',
  ]
draft: false
summary: 'Learn how to build a robust and scalable distributed ID generator using Flask and various backend technologies like Snowflake, Redis, and databases. Ensure uniqueness and high availability in your microservices architecture.'
authors: ['default']
---

# Building a Distributed ID Generator with Flask: Scalable and Unique ID Generation

In modern distributed systems, generating unique IDs across multiple services and data stores can be a challenging task. A naive approach like relying on auto-incrementing IDs from a single database can quickly become a bottleneck and create scalability issues. This article explores different approaches to building a distributed ID generator using Flask, a lightweight Python web framework, to ensure unique and sequential IDs across your microservices architecture.

## Why a Distributed ID Generator?

Before diving into the implementation, let's understand the reasons for using a distributed ID generator:

- **Uniqueness:** Ensures that every ID generated is globally unique across all services and databases.
- **Scalability:** Distributes the load of ID generation across multiple servers, preventing a single point of failure.
- **Performance:** Reduces latency compared to relying on a single database server for ID generation.
- **Database Independence:** Decouples ID generation from specific database technologies, allowing for greater flexibility.
- **Ordered Generation (Optional):** Some distributed ID generation algorithms can generate IDs in a roughly sequential order, which can improve database performance when used as primary keys.

## Approaches to Distributed ID Generation

Several algorithms and technologies can be used to build a distributed ID generator. Here are some of the most common:

1.  **UUIDs (Universally Unique Identifiers):**

    - **Pros:** Simple to implement, guarantees uniqueness, no coordination required.
    - **Cons:** Not sequential, large storage footprint (128 bits), can fragment database indexes.

2.  **Snowflake Algorithm:**

    - **Pros:** Generates roughly sequential IDs, relatively small (64 bits), customizable.
    - **Cons:** Requires coordination to allocate worker IDs, can be sensitive to clock drift.

3.  **Redis-based ID Generation:**

    - **Pros:** Fast and simple, easily scalable, can guarantee sequential IDs.
    - **Cons:** Requires a Redis instance, single point of failure if not properly clustered.

4.  **Database Sequence-based ID Generation:**

    - **Pros:** Reliable, guarantees uniqueness.
    - **Cons:** Centralized, can be a performance bottleneck. This article focuses on mitigating this with sharding.

We'll explore the implementation of Snowflake, Redis and Database sequence-based approaches with Flask. While UUIDs are simple, they often lack the benefits of ordered generation and smaller size offered by alternatives.

## 1. Snowflake Algorithm Implementation

The Snowflake algorithm generates 64-bit IDs with the following structure:

- **1 bit:** Reserved (always 0)
- **41 bits:** Timestamp (milliseconds since epoch)
- **5 bits:** Worker ID (identifies the worker generating the ID)
- **5 bits:** Datacenter ID (identifies the datacenter where the worker is running)
- **12 bits:** Sequence number (incremented for each ID generated within the same millisecond)

This algorithm can generate a huge number of IDs per millisecond per worker (4096).

```plaintext
from flask import Flask, jsonify
import time
import threading

app = Flask(__name__)

class SnowflakeGenerator:
    def __init__(self, worker_id, datacenter_id):
        self.worker_id = worker_id
        self.datacenter_id = datacenter_id
        self.sequence = 0
        self.last_timestamp = -1
        self.worker_id_bits = 5
        self.datacenter_id_bits = 5
        self.sequence_bits = 12
        self.worker_id_shift = self.sequence_bits
        self.datacenter_id_shift = self.sequence_bits + self.worker_id_bits
        self.timestamp_left_shift = self.sequence_bits + self.worker_id_bits + self.datacenter_id_bits
        self.sequence_mask = -1 ^ (-1 << self.sequence_bits)

        # Thread safety using a lock
        self.lock = threading.Lock()

        # Validate worker and datacenter IDs
        max_worker_id = -1 ^ (-1 << self.worker_id_bits)
        max_datacenter_id = -1 ^ (-1 << self.datacenter_id_bits)

        if self.worker_id > max_worker_id or self.worker_id < 0:
            raise ValueError(f"Worker ID cannot be greater than {max_worker_id} or less than 0")
        if self.datacenter_id > max_datacenter_id or self.datacenter_id < 0:
            raise ValueError(f"Datacenter ID cannot be greater than {max_datacenter_id} or less than 0")



    def _time_gen(self):
        return int(time.time() * 1000)

    def _wait_next_millis(self, last_timestamp):
        timestamp = self._time_gen()
        while timestamp <= last_timestamp:
            timestamp = self._time_gen()
        return timestamp

    def get_id(self):
        with self.lock: # Acquire the lock before generating the ID
            timestamp = self._time_gen()

            if timestamp < self.last_timestamp:
                raise Exception(
                    "Clock moved backwards. Refusing to generate id for {} milliseconds".format(
                        self.last_timestamp - timestamp
                    )
                )

            if self.last_timestamp == timestamp:
                self.sequence = (self.sequence + 1) & self.sequence_mask
                if self.sequence == 0:
                    timestamp = self._wait_next_millis(self.last_timestamp)
            else:
                self.sequence = 0

            self.last_timestamp = timestamp

            new_id = (
                (timestamp - 1288834974657) << self.timestamp_left_shift
                | (self.datacenter_id << self.datacenter_id_shift)
                | (self.worker_id << self.worker_id_shift)
                | self.sequence
            )

            return new_id

# Configuration (ensure these are unique for each worker and datacenter)
worker_id = 1
datacenter_id = 1
snowflake = SnowflakeGenerator(worker_id, datacenter_id)


@app.route('/id')
def generate_id():
    new_id = snowflake.get_id()
    return jsonify({'id': new_id})


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
```

**Explanation:**

- **`SnowflakeGenerator` Class:** Encapsulates the Snowflake algorithm logic.
- **`worker_id` and `datacenter_id`:** Crucial configuration. Each instance of the generator _must_ have unique values for these across your distributed system. Consider using environment variables or configuration files to manage these.
- **Timestamp:** Represents the milliseconds since the epoch (January 1, 1970).
- **Sequence Number:** Incremented for each ID generated within the same millisecond.
- **Clock Drift Handling:** The code includes a check for clock drift (`timestamp < self.last_timestamp`). If the clock goes backwards, it raises an exception to prevent ID collisions. This is crucial in distributed systems where clock synchronization can be an issue. You might want to integrate NTP (Network Time Protocol) to keep clocks synchronized.
- **Thread Safety:** The `threading.Lock()` ensures that the `get_id` method is thread-safe, allowing multiple threads to generate IDs concurrently without race conditions. This is especially important when using Flask's built-in development server or other multi-threaded deployment scenarios.
- **Epoch Offset:** The code subtracts `1288834974657` from the timestamp. This is the Twitter Epoch (November 4, 2010). Using a custom epoch allows you to reduce the number of bits required for the timestamp.
- **Error Handling**: Includes validation for worker and datacenter IDs to prevent misconfiguration.

**Running the code:**

1.  Save the code as `snowflake_app.py`.
2.  Run `python snowflake_app.py`.
3.  Access `http://localhost:5000/id` in your browser to generate IDs.

**Important Considerations for Snowflake:**

- **Worker ID Allocation:** Manually assigning worker IDs can be error-prone. Consider using a central service (e.g., Zookeeper, Consul, etcd) to dynamically allocate worker IDs.
- **Clock Synchronization:** Ensure that all servers running the Snowflake algorithm have synchronized clocks using NTP. Significant clock drift can lead to ID collisions.
- **Bit Allocation:** Adjust the number of bits allocated for each section (timestamp, worker ID, datacenter ID, sequence number) based on your specific requirements.

## 2. Redis-based ID Generation

Redis provides a simple and efficient way to generate sequential IDs using its `INCR` command. This command atomically increments a counter and returns the new value.

```plaintext
from flask import Flask, jsonify
import redis

app = Flask(__name__)

# Redis Configuration
redis_host = 'localhost'
redis_port = 6379
redis_db = 0
redis_key = 'id_generator'

# Initialize Redis client
redis_client = redis.Redis(host=redis_host, port=redis_port, db=redis_db)

@app.route('/id')
def generate_id():
    try:
        new_id = redis_client.incr(redis_key)
        return jsonify({'id': new_id})
    except redis.exceptions.ConnectionError:
        return jsonify({'error': 'Could not connect to Redis'}, 500)


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
```

**Explanation:**

- **Redis Configuration:** Configure the Redis host, port, database, and key used for the counter.
- **Redis Client:** Initializes a Redis client using the configured settings.
- **`redis_client.incr(redis_key)`:** Atomically increments the counter associated with `redis_key` and returns the new value.
- **Error Handling:** Includes basic error handling for Redis connection errors.

**Running the code:**

1.  Ensure you have Redis installed and running.
2.  Save the code as `redis_app.py`.
3.  Install the `redis` Python package: `pip install redis`
4.  Run `python redis_app.py`.
5.  Access `http://localhost:5000/id` in your browser to generate IDs.

**Important Considerations for Redis:**

- **Single Point of Failure:** A single Redis instance can be a single point of failure. Use Redis Sentinel or Redis Cluster to ensure high availability.
- **Persistence:** Configure Redis with persistence (RDB or AOF) to prevent losing the counter value in case of a server restart.
- **Performance:** Redis is generally very fast, but performance can degrade if the counter is frequently incremented by multiple clients. Consider using connection pooling or batching to improve performance.
- **Namespace:** Consider using a more descriptive key name for `redis_key` to avoid conflicts with other applications using the same Redis instance. For example, `your_application_name:id_generator`.

## 3. Database Sequence-based ID Generation (with Sharding)

While traditionally a bottleneck, we can use a database's sequence capabilities and mitigate the centralized nature with sharding. This approach leverages separate sequence generators in different database shards.

```plaintext
from flask import Flask, jsonify
import sqlite3
import hashlib
import threading

app = Flask(__name__)

# Database configuration
DATABASE = 'ids.db'
NUM_SHARDS = 4 # Number of database shards
TABLE_NAME = 'ids'
SEQUENCE_NAME = 'id_seq'


# Function to get a database connection for a specific shard
def get_db_connection(shard_id):
    db_name = f'shard_{shard_id}_{DATABASE}'
    conn = sqlite3.connect(db_name)
    conn.row_factory = sqlite3.Row
    return conn

# Initialize database shards
def init_db():
    for shard_id in range(NUM_SHARDS):
        conn = get_db_connection(shard_id)
        cursor = conn.cursor()
        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
                id INTEGER PRIMARY KEY
            );
        """)

        # Create a sequence generator (SQLite doesn't have built-in sequences, so we simulate it)
        cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {SEQUENCE_NAME} (
                next_id INTEGER NOT NULL DEFAULT 1
            );
        """)
        cursor.execute(f"INSERT OR IGNORE INTO {SEQUENCE_NAME} (next_id) VALUES (1);") # Initialize sequence if it doesn't exist

        conn.commit()
        conn.close()

# Function to generate a unique ID for a specific shard
def generate_shard_id(shard_id):
    conn = get_db_connection(shard_id)
    cursor = conn.cursor()
    try:
        cursor.execute(f"UPDATE {SEQUENCE_NAME} SET next_id = next_id + 1 RETURNING next_id;")
        result = cursor.fetchone()
        if result:
            next_id = result[0] #SQLite returns the updated value
            conn.commit()
            return next_id
        else:
            # Handle the unlikely case where the sequence row is deleted
            conn.rollback()
            cursor.execute(f"INSERT OR IGNORE INTO {SEQUENCE_NAME} (next_id) VALUES (1);")
            cursor.execute(f"UPDATE {SEQUENCE_NAME} SET next_id = next_id + 1 RETURNING next_id;")
            result = cursor.fetchone()
            if result:
                next_id = result[0]
                conn.commit()
                return next_id
            else:
                raise Exception("Failed to generate ID (sequence row is missing)") #Severe issue
    except sqlite3.Error as e:
        conn.rollback()
        raise e
    finally:
        conn.close()

# Function to determine the shard ID based on a key (e.g., entity ID)
def get_shard_id(key):
    key_bytes = str(key).encode('utf-8')
    hashed_key = int(hashlib.md5(key_bytes).hexdigest(), 16)
    return hashed_key % NUM_SHARDS


@app.route('/id/<key>')
def generate_id(key):
    try:
        shard_id = get_shard_id(key)
        new_id = generate_shard_id(shard_id)
        return jsonify({'id': new_id, 'shard_id': shard_id})
    except Exception as e:
        return jsonify({'error': str(e)}, 500)


@app.before_first_request
def before_first_request_func():
    init_db()  # Initialize database shards before handling any requests


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
```

**Explanation:**

- **Database Sharding:** The database is divided into multiple shards. Each shard is a separate database file (e.g., `shard_0_ids.db`, `shard_1_ids.db`, etc.).
- **Shard ID Determination:** The `get_shard_id` function determines which shard to use based on the input `key`. In this example, it uses an MD5 hash of the key to distribute IDs across shards. This is important; the key (often representing the entity the ID belongs to) determines the shard.
- **Sequence Generation:** Each shard has its own `SEQUENCE_NAME` table, simulating a sequence generator.
- **`generate_shard_id` Function:** Connects to the appropriate shard, increments the sequence counter, and returns the new ID. It also includes error handling (transaction rollback and sequence row re-creation if necessary).
- **Initialization:** The `init_db` function creates the database shards and the sequence tables. It's called before the first request to ensure the database is properly initialized.
- **`@app.before_first_request`:** This decorator ensures that the `init_db` function is called only once when the application starts.
- **SQLite Simulation:** Since SQLite lacks built-in sequences, we simulate them using a table with an `INTEGER` column (`next_id`).

**Running the code:**

1.  Save the code as `sharded_db_app.py`.
2.  Run `python sharded_db_app.py`.
3.  Access `http://localhost:5000/id/<your_key>` in your browser, replacing `<your_key>` with a unique identifier. For example `http://localhost:5000/id/user123`. The key determines the shard the ID will be generated from.

**Important Considerations for Sharded Database IDs:**

- **Shard Key Selection:** The choice of the shard key is crucial for performance and scalability. The key should be distributed evenly across the shards to avoid hot spots. If your data has inherent locality (e.g., users from a specific region), you can use that to determine the shard.
- **Number of Shards:** The number of shards should be chosen based on your expected data volume and growth rate. Start with a reasonable number of shards and increase as needed.
- **Database Choice:** While this example uses SQLite for simplicity, it's more common to use more robust databases like PostgreSQL or MySQL in production environments. These databases offer built-in sequence features and better scalability.
- **Transaction Management:** Ensure proper transaction management to prevent data corruption in case of errors. The example includes rollback operations in the `generate_shard_id` function.
- **Idempotency:** Consider what happens if an ID generation fails. You may need mechanisms to ensure idempotency (that retrying the operation does not create duplicate IDs).
- **Key Space Collision:** Each shard is independent, meaning IDs generated in separate shards _can_ potentially collide. If you need globally unique and ordered IDs across all shards, you need a more sophisticated approach like prepending the shard ID to the generated ID (but then you're back to a Snowflake-like approach). This approach is most suitable when uniqueness is enforced _within_ the shard (e.g., each shard represents a different table or database entirely).
- **MD5 Hashing**: Using MD5 for sharding is fine for a proof of concept, but for production systems, you should consider stronger hashing algorithms like SHA-256 for better distribution and collision resistance, and potentially consider consistent hashing algorithms if you need to re-shard later.

## Choosing the Right Approach

The best approach for building a distributed ID generator depends on your specific requirements:

- **Snowflake:** Suitable for applications that require roughly sequential IDs and high throughput.
- **Redis:** A good choice for applications that need very fast ID generation and can tolerate a single point of failure (if not using Redis Sentinel or Cluster).
- **Sharded Database IDs:** A reasonable approach when you already have a sharded database architecture and want to leverage existing infrastructure. Requires careful planning and management.
- **UUIDs:** Simple and easy to implement, but not suitable for applications that require sequential IDs or have storage constraints.

## Conclusion

Building a distributed ID generator is crucial for creating scalable and robust distributed systems. By understanding the different approaches and technologies available, you can choose the solution that best fits your needs and ensure the uniqueness and integrity of your data. Remember to consider factors like scalability, performance, fault tolerance, and complexity when making your decision. Always prioritize clear error handling and monitoring to detect and resolve issues promptly. Also, thoroughly test your implementation under high load to identify potential bottlenecks.
