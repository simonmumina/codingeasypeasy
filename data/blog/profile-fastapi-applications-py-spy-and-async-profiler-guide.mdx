---
title: 'Profile FastAPI Applications: py-spy and async-profiler Guide'
date: '2024-01-01'
lastmod: '2024-01-05'
tags:
  [
    'fastapi',
    'profiling',
    'performance',
    'py-spy',
    'async-profiler',
    'python',
    'optimization',
    'performance tuning',
  ]
draft: false
summary: 'Learn how to profile your FastAPI applications using py-spy and async-profiler to identify performance bottlenecks and optimize your code for maximum efficiency. This comprehensive guide includes code examples and best practices.'
authors: ['default']
---

# Profile FastAPI Applications: py-spy and async-profiler Guide

FastAPI is a modern, high-performance, web framework for building APIs with Python. It's known for its speed and ease of use. However, like any application, FastAPI applications can sometimes suffer from performance bottlenecks. Identifying these bottlenecks is crucial for optimization. This guide will walk you through profiling FastAPI applications using two powerful tools: `py-spy` and `async-profiler`.

## Why Profile Your FastAPI Applications?

Before diving into the tools, let's understand why profiling is essential:

- **Identify Bottlenecks:** Profiling helps pinpoint the specific functions or code sections that consume the most time or resources.
- **Optimize Performance:** Once bottlenecks are identified, you can focus your optimization efforts on the most impactful areas.
- **Improve Responsiveness:** Reduced execution time translates to faster response times for your API, leading to a better user experience.
- **Resource Optimization:** Efficient code reduces CPU usage, memory consumption, and overall resource requirements, potentially saving costs on infrastructure.
- **Scalability:** Identifying and addressing performance issues early on allows your application to scale more effectively as your user base grows.

## Introduction to Profiling Tools

We'll be exploring two popular profiling tools:

- **py-spy:** A sampling profiler for Python programs. It allows you to visualize what a Python program is spending its time on without modifying the program or restarting it. It works by sampling the stack frames of the running Python process.
- **async-profiler:** A low-overhead sampling profiler for Java and other languages (including Python via CPython's native code interface). It's particularly well-suited for profiling asynchronous code and provides detailed flame graphs.

## Setting Up a FastAPI Application for Profiling

First, let's create a simple FastAPI application to profile. Create a file named `main.py` with the following content:

```plaintext
from fastapi import FastAPI
from time import sleep
import asyncio

app = FastAPI()


def cpu_bound_function():
    """Simulates a CPU-intensive task."""
    result = 0
    for i in range(1000000):
        result += i * i
    return result


async def io_bound_function():
    """Simulates an I/O-bound task."""
    await asyncio.sleep(1)
    return "I/O operation completed"

@app.get("/cpu")
async def cpu_endpoint():
    """Endpoint that triggers a CPU-bound task."""
    result = cpu_bound_function()
    return {"result": result}

@app.get("/io")
async def io_endpoint():
    """Endpoint that triggers an I/O-bound task."""
    result = await io_bound_function()
    return {"result": result}


@app.get("/")
async def root():
    return {"message": "Hello World"}
```

This example includes:

- `/`: A basic hello world endpoint.
- `/cpu`: An endpoint that executes a CPU-bound function.
- `/io`: An endpoint that executes an I/O-bound function using `asyncio.sleep`.

Install FastAPI and uvicorn:

```bash
pip install fastapi uvicorn
```

Run the application:

```bash
uvicorn main:app --reload
```

## Profiling with py-spy

### Installation

Install `py-spy`:

```bash
pip install py-spy
```

### Profiling the CPU-Bound Endpoint

1.  **Start the FastAPI application:** As shown above using `uvicorn main:app --reload`
2.  **Identify the process ID (PID) of the uvicorn worker:** You can use tools like `ps aux | grep uvicorn` or `top` to find the PID. It will likely be the main uvicorn process, not the reload process if you are using the `--reload` flag.
3.  **Run `py-spy`:**

    ```bash
    py-spy record -o profile.svg -p <PID> --duration 30
    ```

    - `-o profile.svg`: Specifies the output file name (flame graph in SVG format).
    - `-p <PID>`: Specifies the process ID to profile. Replace `<PID>` with the actual PID of the uvicorn worker.
    - `--duration 30`: Specifies the profiling duration in seconds.

4.  **Load the `/cpu` endpoint:** While `py-spy` is running, send requests to the `/cpu` endpoint. You can use `curl`, `httpie`, or a browser.
    For example: `curl http://localhost:8000/cpu` or `http http://localhost:8000/cpu`

5.  **Analyze the Flame Graph:** Open the `profile.svg` file in a web browser. The flame graph will visualize the time spent in different functions. You should see the `cpu_bound_function` taking a significant portion of the time.

### Understanding the py-spy Flame Graph

The flame graph provides a visual representation of the call stack over time.

- **Width of Blocks:** The width of each block represents the amount of time spent in that function. Wider blocks indicate functions that consumed more time.
- **Stacking:** Blocks are stacked on top of each other, representing the call stack at a given point in time. The higher the stack, the deeper the call stack.
- **Color:** The color of the blocks doesn't usually have a specific meaning; it's mainly used for visual differentiation.
- **Navigation:** You can click on a block to zoom in and see its callers and callees. This allows you to navigate the call stack and identify the root cause of performance bottlenecks.

### Profiling the I/O-Bound Endpoint

Profiling I/O-bound code with `py-spy` might not be as insightful as profiling CPU-bound code, because `py-spy` samples the call stack, and I/O-bound code spends a lot of time waiting for I/O operations, which might not be visible in the stack samples. However, you can still use it:

```bash
py-spy record -o io_profile.svg -p <PID> --duration 30
```

Load the `/io` endpoint while `py-spy` is recording. You'll likely see a lot of time spent in the `asyncio.sleep` function, which confirms it's I/O-bound.

## Profiling with async-profiler

`async-profiler` is particularly effective for profiling asynchronous code, as it can track asynchronous contexts. However, setting it up for Python requires some more steps, as it's primarily designed for Java.

### Installation and Setup

1.  **Download async-profiler:** Download the latest release from the [async-profiler GitHub repository](https://github.com/jvm-profiling-tools/async-profiler/releases). You'll want the `async-profiler-<version>-linux-x64.tar.gz` or similar, depending on your operating system. Note that async-profiler works best on Linux.
2.  **Extract the archive:** Extract the downloaded archive to a directory of your choice. For example: `tar -xzf async-profiler-*.tar.gz`
3.  **Install `perfetto`:** `async-profiler` can generate `perfetto` traces, which are visualized using the Perfetto UI. Install `perfetto`:

    ```bash
    sudo apt install perfetto # On Debian/Ubuntu
    # Or use your distribution's package manager
    ```

4.  **Install the `async_profiler` Python package:** This provides a Python API for interacting with async-profiler.

    ```bash
    pip install async_profiler
    ```

5.  **Enable System-Wide PTrace:** async-profiler typically requires `ptrace_scope` to be set to `0`. You might need root privileges for this.

    ```bash
    sudo sysctl kernel.yama.ptrace_scope=0
    ```

    To make this permanent, edit `/etc/sysctl.d/10-ptrace.conf` and add the line `kernel.yama.ptrace_scope = 0`. Then, run `sudo sysctl -p` to apply the changes. **Be aware of the security implications of disabling ptrace scope.** Consider alternatives like using Docker with specific capabilities if security is a concern.

### Profiling the FastAPI Application

Here's how to profile the FastAPI application using `async-profiler`:

```plaintext
from fastapi import FastAPI
from time import sleep
import asyncio
from async_profiler import Profiler  # Import the Profiler

app = FastAPI()

profiler = Profiler(include_async=True)  # Initialize the profiler with async support

def cpu_bound_function():
    """Simulates a CPU-intensive task."""
    result = 0
    for i in range(1000000):
        result += i * i
    return result


async def io_bound_function():
    """Simulates an I/O-bound task."""
    await asyncio.sleep(1)
    return "I/O operation completed"

@app.get("/cpu")
async def cpu_endpoint():
    """Endpoint that triggers a CPU-bound task."""
    profiler.start() # start the profiler when entering the function
    result = cpu_bound_function()
    profiler.stop() # stop the profiler when exiting the function
    return {"result": result}

@app.get("/io")
async def io_endpoint():
    """Endpoint that triggers an I/O-bound task."""
    profiler.start()
    result = await io_bound_function()
    profiler.stop()
    return {"result": result}


@app.get("/")
async def root():
    return {"message": "Hello World"}
```

This modified `main.py` file now includes the `async_profiler` package and starts/stops the profiler around the CPU and IO intensive functions.

**Note:** Replace `<path_to_async_profiler>` with the actual path where you extracted the async-profiler archive. You may need to adjust your PYTHONPATH to include the async_profiler's lib directory, e.g., `export PYTHONPATH=$PYTHONPATH:<path_to_async_profiler>/lib`

Now, start the FastAPI application again:

```bash
uvicorn main:app --reload
```

Run the profiling script (replace `<path_to_async_profiler>`):

```bash
python -m async_profiler --pid <PID> --duration 30 --output profile.html
```

Where:

- `--pid <PID>` is the process ID of the FastAPI application (the Uvicorn worker). Find this using `ps aux | grep uvicorn`.
- `--duration 30` specifies the profiling duration in seconds.
- `--output profile.html` specifies the output file name. You can use formats like `.html` for a self-contained HTML report or `.jfr` (Java Flight Recorder) for more advanced analysis with tools like JMC.
- `--include-async` : This can also be passed to the profiler arguments in the `python -m async_profiler` call.

**Load the Endpoints:** While the profiler is running, load the `/cpu` and `/io` endpoints in your browser or using `curl`.

**Analyze the Results:** Open `profile.html` in your browser. The HTML report will contain a flame graph that visualizes the time spent in different functions, including asynchronous tasks. async-profiler provides more detailed information about asynchronous context switching than `py-spy`. You may need to adjust the sampling rate (`--frequency`) or profiling duration for optimal results.

### Alternate Approach: Using the Python API

Alternatively, you can use the `async_profiler` Python package directly within your FastAPI application for more fine-grained control. This can be useful for profiling specific parts of your code.

```plaintext
from fastapi import FastAPI
from time import sleep
import asyncio
from async_profiler import Profiler
import os

app = FastAPI()

profiler = Profiler(include_async=True)

def cpu_bound_function():
    """Simulates a CPU-intensive task."""
    result = 0
    for i in range(1000000):
        result += i * i
    return result


async def io_bound_function():
    """Simulates an I/O-bound task."""
    await asyncio.sleep(1)
    return "I/O operation completed"

@app.get("/cpu")
async def cpu_endpoint():
    """Endpoint that triggers a CPU-bound task."""
    profiler.start()
    result = cpu_bound_function()
    profiler.stop()
    profiler.dump("cpu_profile.html")
    return {"result": result}

@app.get("/io")
async def io_endpoint():
    """Endpoint that triggers an I/O-bound task."""
    profiler.start()
    result = await io_bound_function()
    profiler.stop()
    profiler.dump("io_profile.html")
    return {"result": result}

@app.get("/")
async def root():
    return {"message": "Hello World"}

# Create profile folder if it doesn't exist
os.makedirs("profiles", exist_ok=True)
```

In this example, the profiler is started and stopped around the CPU and IO intensive functions. The dump method is called to generate profile files after profiling each function. This provides more granular control over the profiling process.

Then, run the FastAPI application:

```bash
uvicorn main:app --reload
```

Access the `/cpu` and `/io` endpoints. The generated profile files `cpu_profile.html` and `io_profile.html` can be found in your working directory.

### Troubleshooting async-profiler

- **Permission Errors:** Ensure you have the necessary permissions to access the process and create output files. Running the profiling command with `sudo` might be necessary in some cases, but be cautious.
- **Incorrect PID:** Double-check that you're using the correct PID for the Uvicorn worker process.
- **async-profiler Path:** Verify that the `async-profiler` path is correctly set and that the required libraries are accessible.

## Choosing the Right Tool

- **py-spy:** Simple to use and install. Good for quickly identifying CPU-bound bottlenecks. Less effective for profiling asynchronous code.
- **async-profiler:** More powerful and accurate for profiling asynchronous code. Requires more setup and configuration. It provides deeper insights into asynchronous context switching and I/O operations.

## Best Practices for Profiling

- **Profile in a Representative Environment:** Profile your application in an environment that closely resembles your production environment (e.g., similar hardware, data volume, and network conditions).
- **Focus on Realistic Workloads:** Simulate realistic user traffic and workloads during profiling to capture accurate performance data.
- **Isolate the Problem:** If possible, try to isolate the specific code sections that you suspect are causing performance issues.
- **Iterate and Measure:** After making optimizations, re-profile your application to measure the impact of your changes.
- **Consider Sampling Rate:** Experiment with different sampling rates in `async-profiler` (using the `--frequency` option) to find a balance between accuracy and overhead. A higher sampling rate provides more detailed information but also increases the profiling overhead.

## Conclusion

Profiling your FastAPI applications is crucial for identifying performance bottlenecks and optimizing your code. `py-spy` provides a quick and easy way to identify CPU-bound bottlenecks, while `async-profiler` offers more powerful and accurate profiling, especially for asynchronous code. By following the steps and best practices outlined in this guide, you can effectively profile your FastAPI applications and improve their performance, responsiveness, and scalability. Remember to always measure the impact of your optimizations and iterate on your approach.
