---
title: 'Handling Late Data in Spark Streaming: Strategies & Code Examples'
date: '2024-02-29'
lastmod: '2024-03-01'
tags: ['spark streaming', 'late data', 'watermarking', 'windowing', 'apache spark', 'data engineering', 'real-time processing']
draft: false
summary: 'Learn how to effectively handle late data in Spark Streaming using techniques like watermarking and windowing. This comprehensive guide provides code examples and best practices to ensure accurate and reliable real-time data processing.'
authors: ['default']
---

# Handling Late Data in Spark Streaming: Strategies & Code Examples

Spark Streaming is a powerful tool for processing real-time data. However, one of the significant challenges in stream processing is dealing with **late data**. Late data refers to data records that arrive after their designated window or processing deadline has passed.  Ignoring late data can lead to inaccurate results and compromise the integrity of your real-time applications. This blog post explores various strategies and techniques to effectively handle late data in Spark Streaming, complete with code examples.

## Understanding the Problem of Late Data

In a perfect world, data would arrive in a timely manner. However, in real-world scenarios, factors such as network delays, system outages, and data source inconsistencies can cause data to arrive late. This is especially prevalent in distributed systems where data flows through multiple hops before reaching the Spark Streaming application.

Consider a scenario where you're calculating the average temperature over 5-minute windows. If a temperature reading for a specific timestamp arrives 10 minutes after the end of its window, it would normally be discarded.  This discarded data impacts the accuracy of the average temperature calculation for that window.

## Strategies for Handling Late Data

Here are several strategies to address the late data problem in Spark Streaming:

1.  **Watermarking:**

    Watermarking is a core mechanism in Spark Streaming for handling late data. It defines a threshold beyond which data is considered "too late" and will be dropped or handled in a specific way.  The watermark is based on the event time of the data records, not the processing time.

    **How it works:**

    *   You specify a delay threshold (e.g., 10 minutes).
    *   Spark Streaming tracks the maximum event time it has seen so far.
    *   The watermark is calculated as `maximum event time - delay threshold`.
    *   Data records with an event time older than the watermark are considered late.

    **Code Example (Scala):**

    ```scala
    import org.apache.spark.sql.SparkSession
    import org.apache.spark.sql.functions._
    import org.apache.spark.sql.streaming.{OutputMode, Trigger}

    object LateDataHandling {
      def main(args: Array[String]): Unit = {

        val spark = SparkSession.builder()
          .appName("LateDataHandling")
          .master("local[*]") // Change to your cluster manager
          .getOrCreate()

        import spark.implicits._

        // Sample data stream (replace with your actual source)
        val dataStream = spark.readStream
          .format("socket")
          .option("host", "localhost")
          .option("port", 9999)
          .load()
          .as[String] // Assuming each line is a string of comma-separated values

        // Define schema (eventTime, value)
        case class Event(eventTime: Long, value: Int)

        // Transform the data
        val events = dataStream.map(line => {
          val parts = line.split(",")
          Event(parts(0).toLong, parts(1).toInt) // Parse data
        })

        // Apply windowing and watermarking
        val windowedCounts = events
          .withWatermark("eventTime", "10 minutes") // Watermark with 10 minutes delay
          .groupBy(
            window($"eventTime", "5 minutes", "5 minutes") // 5-minute window, slide every 5 minutes
          )
          .agg(sum($"value").as("total_value"))


        // Output the results (Append Mode)
        val query = windowedCounts.writeStream
          .outputMode(OutputMode.Append()) // AppendMode is suitable for this use case
          .trigger(Trigger.ProcessingTime("10 seconds")) // Check for new data every 10 seconds
          .format("console")
          .start()

        query.awaitTermination()
      }
    }
    ```

    **Explanation:**

    *   `withWatermark("eventTime", "10 minutes")`:  Sets the watermark based on the `eventTime` column, with a 10-minute delay.  Data older than `max(eventTime) - 10 minutes` will be considered late.
    *   `groupBy(window($"eventTime", "5 minutes", "5 minutes"))`: Defines a 5-minute window that slides every 5 minutes.
    *   `OutputMode.Append()`:  Only outputs new aggregates after each batch.  Crucially, this works with watermarks because Spark maintains state for late data to be handled.

    **Important Considerations:**

    *   **Event Time:** You *must* have a column representing the event time in your data.
    *   **Watermark Delay:** Choose an appropriate delay threshold based on your data characteristics and acceptable latency.  Too short, and you'll discard valid data; too long, and you'll increase latency.
    *   **Output Mode:**  Watermarking requires a stateful operation (like `groupBy` and `agg`).  Therefore, only `Append`, `Update`, and `Complete` output modes are supported.  `Append` is often the most efficient.
    *   **Starting Spark Streaming:** You'll need to send data to the socket (e.g., using `nc -lk 9999`) in the format "timestamp,value".  For example: `1677686400000,10` (timestamp in milliseconds).  Ensure your timestamps are in chronological order *mostly* for testing the watermark.
    *   **Real-World Sources:** Replace the socket stream with your actual data source (e.g., Kafka, Kinesis, Azure Event Hubs).

2.  **Updating Aggregates for Late Data:**

    Instead of dropping late data, you can update existing aggregates. This is particularly useful when you're tracking counts, sums, or averages.

    **Code Example (Scala):**

    ```scala
    import org.apache.spark.sql.SparkSession
    import org.apache.spark.sql.functions._
    import org.apache.spark.sql.streaming.{OutputMode, Trigger}

    object LateDataUpdate {
      def main(args: Array[String]): Unit = {

        val spark = SparkSession.builder()
          .appName("LateDataUpdate")
          .master("local[*]")
          .getOrCreate()

        import spark.implicits._

        // Sample data stream (replace with your actual source)
        val dataStream = spark.readStream
          .format("socket")
          .option("host", "localhost")
          .option("port", 9999)
          .load()
          .as[String]

        case class Event(eventTime: Long, value: Int)

        val events = dataStream.map(line => {
          val parts = line.split(",")
          Event(parts(0).toLong, parts(1).toInt)
        })

        val windowedCounts = events
          .withWatermark("eventTime", "10 minutes")
          .groupBy(
            window($"eventTime", "5 minutes", "5 minutes")
          )
          .agg(sum($"value").as("total_value"))

        // Use Update Output Mode to update existing aggregates with late data
        val query = windowedCounts.writeStream
          .outputMode(OutputMode.Update())  // Key change: Update Mode
          .trigger(Trigger.ProcessingTime("10 seconds"))
          .format("console")
          .start()

        query.awaitTermination()
      }
    }
    ```

    **Explanation:**

    *   The key difference is using `OutputMode.Update()`.  This mode allows Spark to update the output table whenever new data (including late data) arrives that affects existing aggregates.  Spark maintains the state of the aggregates, so it can update them.

    **When to use `Update` mode:**

    *   When you need the most accurate aggregates, even if it means some updates to previously emitted results.
    *   When the impact of late data is significant enough to warrant the overhead of updating aggregates.

3.  **Storing Late Data in a Separate Sink:**

    Instead of updating aggregates directly, you can store late data in a separate sink (e.g., a separate Kafka topic, a database table, or a file). This allows you to analyze the late data separately, identify patterns, and potentially reprocess it later.

    **Code Example (Scala):**

    ```scala
    import org.apache.spark.sql.SparkSession
    import org.apache.spark.sql.functions._
    import org.apache.spark.sql.streaming.{OutputMode, Trigger}
    import org.apache.spark.sql.Dataset

    object LateDataSink {
      def main(args: Array[String]): Unit = {

        val spark = SparkSession.builder()
          .appName("LateDataSink")
          .master("local[*]")
          .getOrCreate()

        import spark.implicits._

        // Sample data stream (replace with your actual source)
        val dataStream = spark.readStream
          .format("socket")
          .option("host", "localhost")
          .option("port", 9999)
          .load()
          .as[String]

        case class Event(eventTime: Long, value: Int)

        val events = dataStream.map(line => {
          val parts = line.split(",")
          Event(parts(0).toLong, parts(1).toInt)
        })

        // Define a watermark
        val eventsWithWatermark = events.withWatermark("eventTime", "10 minutes")

        // Get windowed counts (for the main pipeline)
        val windowedCounts = eventsWithWatermark
          .groupBy(
            window($"eventTime", "5 minutes", "5 minutes")
          )
          .agg(sum($"value").as("total_value"))

        // Filter out late data
        val lateData: Dataset[Event] = events.join(windowedCounts, events("eventTime") === windowedCounts("window.start") && events("value") === windowedCounts("total_value"), "left_anti").as[Event]


        //Write results for non-late data
        val queryMain = windowedCounts.writeStream
          .outputMode(OutputMode.Append())
          .trigger(Trigger.ProcessingTime("10 seconds"))
          .format("console")
          .start()


        // Write late data to a separate location (e.g., a different Kafka topic or a file)
        val queryLate = lateData.writeStream
          .outputMode(OutputMode.Append())
          .trigger(Trigger.ProcessingTime("10 seconds"))
          .format("console") // Or "kafka", "parquet", etc.
          .start()

        queryMain.awaitTermination()
        queryLate.awaitTermination()
      }
    }
    ```

    **Explanation:**

    *   `events.join(windowedCounts, events("eventTime") === windowedCounts("window.start") && events("value") === windowedCounts("total_value"), "left_anti").as[Event]` identifies late data.
    *   We create separate write streams: one for the main pipeline (windowed counts) and one for the late data.
    *   The `format` option for the late data stream can be set to your desired destination (e.g., `"kafka"`, `"parquet"`, `"csv"`).

    **Benefits:**

    *   Preserves all data, even if it's late.
    *   Allows for separate analysis and reprocessing of late data.
    *   Keeps the main pipeline cleaner and more focused on timely data.

4.  **Using `allowedLatness` with Aggregate Functions:**

    In some cases, you might want to extend the window duration to accommodate some degree of lateness.  Spark Streaming provides the `allowedLatness` option for aggregate functions to achieve this.

    **Note:** As of Spark 3.0, `allowedLatness` is deprecated and replaced by `withWatermark` as a more flexible and efficient solution.  The following example shows a deprecated syntax, which is for illustrative purposes only.

    ```scala
    //DEPRECATED EXAMPLE
    //import org.apache.spark.sql.SparkSession
    //import org.apache.spark.sql.functions._
    //import org.apache.spark.sql.streaming.{OutputMode, Trigger}

    //object AllowedLatnessExample {
    //  def main(args: Array[String]): Unit = {

    //    val spark = SparkSession.builder()
    //      .appName("AllowedLatnessExample")
    //      .master("local[*]")
    //      .getOrCreate()

    //    import spark.implicits._

    //    // Sample data stream (replace with your actual source)
    //    val dataStream = spark.readStream
    //      .format("socket")
    //      .option("host", "localhost")
    //      .option("port", 9999)
    //      .load()
    //      .as[String]

    //    case class Event(eventTime: Long, value: Int)

    //    val events = dataStream.map(line => {
    //      val parts = line.split(",")
    //      Event(parts(0).toLong, parts(1).toInt)
    //    })

    //    //THIS IS A DEPRECATED APPROACH
    //    val windowedCounts = events
    //      .groupBy(
    //        window($"eventTime", "5 minutes", "5 minutes")
    //      )
    //      .agg(sum($"value").as("total_value"))
    //      .withWatermark("eventTime", "10 minutes")

    //    val query = windowedCounts.writeStream
    //      .outputMode(OutputMode.Append())
    //      .trigger(Trigger.ProcessingTime("10 seconds"))
    //      .format("console")
    //      .start()

    //    query.awaitTermination()
    //  }
    //}
    ```

    **Recommendation:** Always use `withWatermark` instead of `allowedLatness`.  It's the recommended and more powerful approach for handling late data.  The previous example shows how to achieve the same result using `withWatermark`.

## Best Practices for Handling Late Data

*   **Define Clear SLAs:**  Establish clear Service Level Agreements (SLAs) for data latency. This will help you determine an acceptable watermark delay.
*   **Monitor Data Latency:**  Implement monitoring to track data latency and identify potential issues. This allows you to proactively adjust your watermark delay if necessary.
*   **Choose the Right Output Mode:**  Carefully select the appropriate output mode based on your requirements. `Append` is generally the most efficient, but `Update` might be necessary if you need to update existing aggregates.
*   **Test Thoroughly:**  Test your Spark Streaming application thoroughly with various late data scenarios to ensure it behaves as expected.
*   **Consider Idempotency:** If you're updating external systems with the processed data, ensure your operations are idempotent (i.e., performing the same operation multiple times has the same effect as performing it once). This is important because late data might cause updates to be applied multiple times.

## Conclusion

Handling late data is crucial for building reliable and accurate real-time data processing applications with Spark Streaming. By using techniques like watermarking, updating aggregates, and storing late data in separate sinks, you can mitigate the impact of late data and ensure the integrity of your results.  Remember to choose the right strategy based on your specific requirements and data characteristics.  Prioritize using `withWatermark` as the primary mechanism for managing late data in Spark Streaming.  By following the best practices outlined in this guide, you can confidently build robust and resilient Spark Streaming applications.