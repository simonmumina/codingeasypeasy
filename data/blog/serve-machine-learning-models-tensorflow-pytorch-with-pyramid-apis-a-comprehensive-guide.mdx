---
title: 'Serve Machine Learning Models (TensorFlow, PyTorch) with Pyramid APIs: A Comprehensive Guide'
date: '2024-02-29'
lastmod: '2024-02-29'
tags:
  [
    'machine learning',
    'mlops',
    'api',
    'pyramid',
    'tensorflow',
    'pytorch',
    'model serving',
    'deployment',
    'python',
    'web api',
  ]
draft: false
summary: 'Learn how to effectively serve your TensorFlow and PyTorch machine learning models via robust and scalable Pyramid APIs. This comprehensive guide covers everything from model loading to API endpoint creation and testing, ensuring seamless integration with your applications.'
authors: ['default']
---

# Serve Machine Learning Models (TensorFlow, PyTorch) with Pyramid APIs: A Comprehensive Guide

This guide will walk you through the process of serving your machine learning models (TensorFlow and PyTorch) using the Pyramid web framework. Pyramid is a lightweight, flexible Python web framework that provides a solid foundation for building robust and scalable APIs. This approach allows you to easily integrate your trained models into your applications and make predictions programmatically.

## Why Pyramid for Serving ML Models?

Pyramid offers several advantages for serving ML models:

- **Flexibility:** Pyramid is highly configurable, allowing you to customize the framework to fit your specific needs.
- **Scalability:** Pyramid is designed to handle high traffic loads, making it suitable for production environments.
- **Testability:** Pyramid provides excellent support for testing, ensuring the reliability of your API.
- **Integration:** Pyramid seamlessly integrates with various databases, authentication mechanisms, and other Python libraries.
- **Clean Architecture:** Pyramid encourages a structured and organized approach to building APIs, leading to maintainable code.

## Prerequisites

Before we begin, ensure you have the following installed:

- **Python (3.7 or higher):** You can download it from the official Python website.
- **pip:** The Python package installer (usually included with Python).
- **Virtualenv (optional, but recommended):** For creating isolated Python environments.

We will also install the necessary Python packages within our virtual environment.

## Step 1: Setting up the Project Environment

1.  **Create a Project Directory:**

    ```bash
    mkdir ml_api_pyramid
    cd ml_api_pyramid
    ```

2.  **Create a Virtual Environment (Recommended):**

    ```bash
    python3 -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate   # On Windows
    ```

3.  **Install Required Packages:**

    ```bash
    pip install pyramid pyramid-jinja2 tensorflow pillow  # For TensorFlow example
    pip install torch torchvision torchaudio pillow pyramid pyramid-jinja2 # For PyTorch example
    ```

    - `pyramid`: The Pyramid web framework.
    - `pyramid-jinja2`: For rendering responses using Jinja2 templates (optional).
    - `tensorflow` or `torch`: The respective machine learning libraries.
    - `pillow`: Python Imaging Library for image processing (common for ML tasks).
    - `torchvision` and `torchaudio`: Only needed if you are using the PyTorch example with images or audio respectively.

## Step 2: Choosing a Model (TensorFlow or PyTorch)

For this guide, we will provide examples for both TensorFlow and PyTorch. You can adapt these examples to your specific model architecture and data.

### TensorFlow Example: Simple MNIST Model

Let's assume you have a trained TensorFlow model for MNIST digit classification. If not, you can quickly train one:

```plaintext
import tensorflow as tf

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Preprocess the data
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Reshape the data to (number_of_samples, height, width, number_of_channels)
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)


# Build the model
model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
  tf.keras.layers.MaxPooling2D((2, 2)),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=2)

# Save the model
model.save('mnist_model.h5')

print("Model trained and saved as mnist_model.h5")
```

### PyTorch Example: Simple Image Classification Model

Similarly, let's consider a pre-trained PyTorch model for image classification (using a simple convolutional neural network). If you don't have one, train a basic one:

```plaintext
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Define the model
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc = nn.Linear(32 * 7 * 7, 10)  # Assuming input image size of 28x28

    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        x = x.view(-1, 32 * 7 * 7)
        x = self.fc(x)
        return x

# Define the data transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Load the MNIST dataset
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

# Create data loaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Instantiate the model
model = SimpleCNN()

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
num_epochs = 2
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)

        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                   .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))

# Save the model
torch.save(model.state_dict(), 'pytorch_model.pth')
print("Model trained and saved as pytorch_model.pth")
```

## Step 3: Creating the Pyramid Application

1.  **Create the Main Application File ( `main.py` ):**

    ```plaintext
    from pyramid.config import Configurator
    from pyramid.response import Response
    import tensorflow as tf  # For TensorFlow example
    import torch           # For PyTorch example
    from PIL import Image    # For image handling

    # Global variable to hold the loaded model
    model = None
    MODEL_TYPE = "tensorflow" # or "pytorch"
    MODEL_PATH = "mnist_model.h5" # for tensorflow
    #MODEL_PATH = "pytorch_model.pth"  # for pytorch

    def load_model():
        """Loads the machine learning model based on the specified type."""
        global model, MODEL_TYPE, MODEL_PATH
        if MODEL_TYPE == "tensorflow":
            model = tf.keras.models.load_model(MODEL_PATH)
        elif MODEL_TYPE == "pytorch":
            # Define your PyTorch model architecture (same as during training)
            class SimpleCNN(torch.nn.Module):
                def __init__(self):
                    super(SimpleCNN, self).__init__()
                    self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
                    self.relu1 = torch.nn.ReLU()
                    self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)
                    self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
                    self.relu2 = torch.nn.ReLU()
                    self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)
                    self.fc = torch.nn.Linear(32 * 7 * 7, 10)  # Assuming input image size of 28x28

                def forward(self, x):
                    x = self.pool1(self.relu1(self.conv1(x)))
                    x = self.pool2(self.relu2(self.conv2(x)))
                    x = x.view(-1, 32 * 7 * 7)
                    x = self.fc(x)
                    return x

            model = SimpleCNN()
            model.load_state_dict(torch.load(MODEL_PATH))
            model.eval() # Set the model to evaluation mode
        else:
            raise ValueError("Invalid MODEL_TYPE. Must be 'tensorflow' or 'pytorch'.")
        print(f"Model loaded successfully from {MODEL_PATH} (Type: {MODEL_TYPE})")


    def predict_tensorflow(image_path):
        """Performs prediction using the loaded TensorFlow model."""
        global model
        img = Image.open(image_path).convert('L') # Convert to grayscale
        img = img.resize((28, 28))
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = tf.expand_dims(img_array, 0)  # Add batch dimension
        img_array = img_array / 255.0  # Normalize
        prediction = model.predict(img_array)
        predicted_class = int(tf.argmax(prediction, axis=1)[0])
        return predicted_class

    def predict_pytorch(image_path):
        """Performs prediction using the loaded PyTorch model."""
        global model
        transform = transforms.Compose([
            transforms.Resize((28, 28)),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        img = Image.open(image_path).convert('L') # Convert to grayscale
        img = transform(img).unsqueeze(0) # Add batch dimension
        with torch.no_grad():
            output = model(img)
            _, predicted_class = torch.max(output.data, 1)
        return int(predicted_class.item())


    def prediction_view(request):
        """API endpoint for making predictions."""
        try:
            image = request.POST['image'].file
            filename = request.POST['image'].filename
            temp_path = '/tmp/' + filename  # Create a temporary file path
            with open(temp_path, 'wb') as output_file:
                output_file.write(image.read())
            if MODEL_TYPE == "tensorflow":
                predicted_class = predict_tensorflow(temp_path)
            elif MODEL_TYPE == "pytorch":
                predicted_class = predict_pytorch(temp_path)
            else:
                return Response("Error: Invalid MODEL_TYPE", status=500)

            return Response(f"Predicted Class: {predicted_class}")

        except Exception as e:
            return Response(f"Error processing image: {str(e)}", status=500)


    def main(global_config, **settings):
        """ This function returns a Pyramid WSGI application."""
        with Configurator(settings=settings) as config:
            config.add_route('predict', '/predict')
            config.add_view(prediction_view, route_name='predict', request_method='POST')
        load_model()  # Load the model when the application starts
        return config.make_wsgi_app()

    if __name__ == '__main__':
        from pyramid.paster import get_app
        app = get_app({}, 'main')  # Replace 'main' with the name of your app in development.ini if different
        from waitress import serve
        load_model()
        serve(app, host='0.0.0.0', port=6543)
    ```

    **Explanation:**

    - **Imports:** Imports necessary libraries for Pyramid, TensorFlow/PyTorch, and image processing.
    - **`load_model()` Function:** This function loads your pre-trained TensorFlow/PyTorch model. It initializes the `model` global variable. Make sure to replace `"mnist_model.h5"` or `"pytorch_model.pth"` with the correct path to your saved model file. The PyTorch version includes the model definition and the loading of the saved weights.
    - **`predict_tensorflow(image_path)` / `predict_pytorch(image_path)` Functions:** These functions take an image file path as input, preprocess the image, and use the loaded model to make a prediction. It returns the predicted class. The preprocessing steps are tailored to the MNIST dataset (resizing to 28x28, converting to grayscale, normalizing). Adapt these steps based on your model's input requirements.
    - **`prediction_view(request)` Function:** This is the API endpoint that handles incoming requests. It receives the image data, saves it to a temporary file, calls the `predict_tensorflow` or `predict_pytorch` function, and returns the prediction as a response. It handles potential errors during image processing. It expects the image to be sent in a `POST` request with the field name `image`. A temporary file is created as writing directly to `request.POST['image'].file` is not supported.
    - **`main(global_config, **settings)` Function:** This is the entry point for the Pyramid application.  It configures the application, defines the route (`/predict`), and associates the `prediction_view`function with that route for`POST`requests.  It also calls`load_model()` to load the model when the application starts.
    - `if __name__ == '__main__':`: This block of code runs when the script is executed directly (not imported). It starts the Pyramid application using the `waitress` WSGI server.

2.  **Create a Configuration File (`development.ini`):**

    This file configures the Pyramid application for development.

    ```ini
    [app:main]
    use = egg:Pyramid

    pyramid.reload_templates = true
    pyramid.debug_authorization = false
    pyramid.debug_notfound = false
    pyramid.debug_routematch = false
    pyramid.default_locale_name = en

    [server:main]
    use = egg:waitress#main
    host = 0.0.0.0
    port = 6543
    ```

## Step 4: Running the Application

1.  **Start the Pyramid Application:**

    ```bash
    pserve development.ini --reload
    ```

    This command starts the Pyramid development server, which will automatically reload the application when you make changes to the code. The `--reload` flag is useful during development.

## Step 5: Testing the API

You can test the API using `curl`, `Postman`, or any other HTTP client.

**Using `curl`:**

1.  **Prepare an Image:** Choose an image file that represents a digit. For example, you can download a digit image from the MNIST dataset or create your own.

2.  **Send the Request:**

    ```bash
    curl -X POST -F "image=@path/to/your/digit_image.png" http://localhost:6543/predict
    ```

    Replace `path/to/your/digit_image.png` with the actual path to your image file.

**Using Python `requests` library:**

```plaintext
import requests

url = "http://localhost:6543/predict"
files = {'image': open('path/to/your/digit_image.png', 'rb')}  # Replace with your image path
response = requests.post(url, files=files)

print(response.text)
```

**Expected Output:**

The response should be something like:

```
Predicted Class: 7
```

## Step 6: Deployment Considerations

- **WSGI Server:** For production deployments, use a robust WSGI server like Gunicorn or uWSGI instead of the built-in `waitress` server.

- **Load Balancing:** Distribute traffic across multiple instances of your API using a load balancer.

- **Monitoring:** Implement monitoring to track the performance and health of your API.

- **Security:** Secure your API with authentication and authorization mechanisms.

- **Containerization (Docker):** Containerize your application using Docker to ensure consistent deployments across different environments.

- **Model Versioning:** Implement a system for versioning your models so you can easily roll back to previous versions if necessary.

## Troubleshooting

- **ModuleNotFoundError:** Make sure all required packages are installed in your virtual environment.

- **Image Processing Errors:** Double-check the image preprocessing steps in the `predict` function to ensure they match the input requirements of your model. Specifically, check the image size, color space, and normalization.

- **Model Loading Errors:** Verify that the path to your model file is correct and that the model file is not corrupted. Ensure you have the correct versions of TensorFlow or PyTorch installed.

- **Permission Errors:** Ensure that the user running the Pyramid application has the necessary permissions to read the model file and write to the temporary directory ( `/tmp/` ).

## Conclusion

This guide provides a comprehensive approach to serving machine learning models (TensorFlow and PyTorch) using the Pyramid web framework. By following these steps, you can create robust, scalable, and easily maintainable APIs for your ML models. Remember to adapt the code examples to your specific model architecture, data, and deployment environment. Consider the deployment considerations outlined above for production deployments.
